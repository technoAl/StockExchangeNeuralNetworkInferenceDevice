{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import mygrad as mg\n",
    "import numpy as np\n",
    "import re\n",
    "from mynn.layers.dense import dense\n",
    "from mynn.initializers.glorot_normal import glorot_normal\n",
    "from mynn.optimizers.adam import Adam\n",
    "from mygrad.nnet.losses import softmax_crossentropy\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from noggin import create_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(\"glove.6B.50d.txt.w2v\", binary=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running this file trains an argument quality model and saves it to a file ArgumentQualityModel.npy.\n",
    "Do not run this every time you want to test the model on your data.\n",
    "Only run this once at the beginning to create the ArgumentQuality.npy file\n",
    "    or to retrain the model.\n",
    "This file should take a few minutes to run as it trains over 10 epochs on thousands of data items.\n",
    "\"\"\"\n",
    "\n",
    "# Loads glove, which contains english words and their embeddings into 50-dimensional vectors\n",
    "\n",
    "\n",
    "\n",
    "def l2loss(pred, actual):  # L2 loss function (mean square distance)\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred: Union[mygrad.Tensor, numpy.ndarray]\n",
    "        A tensor or numpy array containing the model's predicted values\n",
    "    actual: Union[mygrad.Tensor, numpy.ndarray]\n",
    "        A tensor or numpy array containing the actual values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mg.Tensor\n",
    "        A tensor containing the mean square distance between the prediction and actual values.\n",
    "    \"\"\"\n",
    "    return mg.mean(mg.square(pred - actual))\n",
    "class RNN:  # The RNN class, which passes the data through a gated recurrent unit to convert each sentence into an array\n",
    "    def __init__(self, dim_input, dim_recurrent, dim_output):\n",
    "        \"\"\" Initializes all layers needed for RNN\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dim_input: int\n",
    "            Dimensionality of data passed to RNN (C)\n",
    "\n",
    "        dim_recurrent: int\n",
    "            Dimensionality of hidden state in RNN (D)\n",
    "\n",
    "        dim_output: int\n",
    "            Dimensionality of output of RNN (K)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.fc_h2y = dense(dim_recurrent, dim_output, weight_initializer=glorot_normal)\n",
    "        self.Uz = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wz = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.bz = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "        self.Ur = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wr = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.br = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "        self.Uh = mg.Tensor(\n",
    "            np.random.randn(dim_input * dim_recurrent).reshape(dim_input, dim_recurrent)\n",
    "        )\n",
    "        self.Wh = mg.Tensor(\n",
    "            np.random.randn(dim_recurrent * dim_recurrent).reshape(\n",
    "                dim_recurrent, dim_recurrent\n",
    "            )\n",
    "        )\n",
    "        self.bh = mg.Tensor(np.random.randn(dim_recurrent))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\" Performs the full forward pass for the RNN.\n",
    "\n",
    "        Note that we only care about the last y - the final classification scores for the full sequence\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Union[numpy.ndarray, mygrad.Tensor], shape=(T, C)\n",
    "            The one-hot encodings for the sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mygrad.Tensor, shape=(1, K)\n",
    "            The final classification of the sequence\n",
    "        \"\"\"\n",
    "\n",
    "        h = mg.nnet.gru(\n",
    "            x,\n",
    "            self.Uz,\n",
    "            self.Wz,\n",
    "            self.bz,\n",
    "            self.Ur,\n",
    "            self.Wr,\n",
    "            self.br,\n",
    "            self.Uh,\n",
    "            self.Wh,\n",
    "            self.bh,\n",
    "        )\n",
    "        return self.fc_h2y(h[-1])\n",
    "\n",
    "    @property\n",
    "    def parameters(self):\n",
    "        \"\"\" A convenience function for getting all the parameters of our model.\n",
    "\n",
    "        This can be accessed as an attribute, via `model.parameters`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[Tensor, ...]\n",
    "            A tuple containing all of the learnable parameters for our model\n",
    "        \"\"\"\n",
    "        return self.fc_h2y.parameters + (self.Uz, self.Wz, self.bz, self.Ur, self.Wr, self.br, self.Uh, self.Wh, self.bh)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_dates = []\n",
    "y_dates = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File Reading\n",
    "\"\"\"\n",
    "a = []\n",
    "for i in range(32):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(file.name)\n",
    "    except:\n",
    "        print(\"10/\"+str(i))\n",
    "for i in range(32):\n",
    "    if i != 10:\n",
    "        try:\n",
    "            for j in range(100):\n",
    "                with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                    try:\n",
    "                        a.append(str(file.read()))\n",
    "                    except Exception as e:\n",
    "                        print(file.name)\n",
    "        except:\n",
    "            print(\"11/\"+str(i))\n",
    "            \n",
    "for i in range(32):\n",
    "    if i != 10:\n",
    "        try:\n",
    "            for j in range(100):\n",
    "                with open(\"../TrainingData/TeslaTrainingData_2019-12-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                    try:\n",
    "                        a.append(str(file.read()))\n",
    "                    except Exception as e:\n",
    "                        print(file.name)\n",
    "        except:\n",
    "            print(\"11/\"+str(i))\n",
    "print(len(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = np.array(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Formats data labels\n",
    "\"\"\"\n",
    "def toFinal(a):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > 0:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads and formats data labels\n",
    "\"\"\"\n",
    "y_train = []\n",
    "for i in range(32):\n",
    "    try:\n",
    "        with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "            j = file.read().split(',')[1]\n",
    "            assert j is not None\n",
    "            j = j.replace('\\n','')\n",
    "            for _ in range(100):\n",
    "                y_train.append(float(j))\n",
    "    except:\n",
    "        print(\"Bad: 10/\"+str(i))\n",
    "for i in range(32):\n",
    "    try:\n",
    "        with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "            j = file.read().split(',')[1]\n",
    "            assert j is not None\n",
    "            j = j.replace('\\n','')\n",
    "            for _ in range(100):\n",
    "                y_train.append(float(j))\n",
    "    except:\n",
    "        print(\"Bad: 11/\"+str(i))\n",
    "    \n",
    "for i in range(32):\n",
    "    try:\n",
    "        with open(\"../TrainingData/TeslaTrainingData_2019-12-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "            j = file.read().split(',')[1]\n",
    "            assert j is not None\n",
    "            j = j.replace('\\n','')\n",
    "            for _ in range(100):\n",
    "                y_train.append(float(j))\n",
    "    except:\n",
    "        print(\"Bad: 12/\"+str(i))\n",
    "toFinal(y_train)\n",
    "# print(y_train)\n",
    "y_train = np.array(y_train)\n",
    "# print(y_train)\n",
    "\n",
    "x_test = x_train[3600:]\n",
    "x_train = x_train[:3600]\n",
    "\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(np.count_nonzero(y_train))\n",
    "print(y_train.size)\n",
    "y_test = y_train[1200:1500]\n",
    "y_train = y_train[:1200]\n",
    "x_test = x_train[1200:1500]\n",
    "x_train = x_train[:1200]\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Trains Model\n",
    "\"\"\"\n",
    "dim_input = 50\n",
    "dim_recurrent = 20\n",
    "dim_output = 2\n",
    "plotter, fig, ax = create_plot(metrics=[\"loss\"])\n",
    "rnn = RNN(dim_input, dim_recurrent, dim_output)\n",
    "optimizer = Adam(rnn.parameters)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "# Trains the model over 10 epochs.\n",
    "for epoch_cnt in range(50):\n",
    "    idxs = np.arange(len(x_train))\n",
    "    np.random.shuffle(idxs)\n",
    "    print(\"training epoch number \", epoch_cnt)\n",
    "\n",
    "    for batch_cnt in range(0, len(x_train) // batch_size):\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]\n",
    "        \n",
    "        old = x_train[batch_indices]\n",
    "        batch = np.ascontiguousarray(np.swapaxes(old, 0, 1))\n",
    "        prediction = rnn(batch)\n",
    "        #print(prediction.shape)\n",
    "        truth = ytrain[batch_indices]\n",
    "        #print(\"pred: \", prediction)\n",
    "        #print(\"truth: \", truth)\n",
    "        loss = softmax_crossentropy(prediction, truth)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        loss.null_gradients()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(y_test[y_test==0]))\n",
    "print(len(y_test[y_test==1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}