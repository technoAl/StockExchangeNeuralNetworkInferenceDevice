{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format(\"glove.6B.50d.txt.w2v\", binary=False) # Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38497   0.80092   0.064106 -0.28355  -0.026759 -0.34532  -0.64253\n",
      " -0.11729  -0.33257   0.55243  -0.087813  0.9035    0.47102   0.56657\n",
      "  0.6985   -0.35229  -0.86542   0.90573   0.03576  -0.071705 -0.12327\n",
      "  0.54923   0.47005   0.35572   1.2611   -0.67581  -0.94983   0.68666\n",
      "  0.3871   -1.3492    0.63512   0.46416  -0.48814   0.83827  -0.9246\n",
      " -0.33722   0.53741  -1.0616   -0.081403 -0.67111   0.30923  -0.3923\n",
      " -0.55002  -0.68827   0.58049  -0.11626   0.013139 -0.57654   0.048833\n",
      "  0.67204 ]\n",
      "[-0.41486   0.71848  -0.3045    0.87445   0.22441  -0.56488  -0.37566\n",
      " -0.44801   0.61347  -0.11359   0.74556  -0.10598  -1.1882    0.50974\n",
      "  1.3511    0.069851  0.73314   0.26773  -1.1787   -0.148     0.039853\n",
      "  0.033107 -0.27406   0.25125   0.41507  -1.6188   -0.81778  -0.73892\n",
      " -0.28997   0.57277   3.4719    0.73817  -0.044495 -0.15119  -0.93503\n",
      " -0.13152  -0.28562   0.76327  -0.83332  -0.6793   -0.39099  -0.64466\n",
      "  1.0044   -0.2051    0.46799   0.99314  -0.16221  -0.46022  -0.37639\n",
      " -0.67542 ]\n",
      "[-0.2349   -1.2784    0.63754   0.44045   0.6878   -0.24104  -0.82718\n",
      " -0.79215   0.3717   -0.1376    0.32629   0.38375  -0.39701   0.28995\n",
      " -0.80867   0.2974    0.48053  -0.079168 -0.65351   0.23873   0.63859\n",
      "  0.096386  0.073431  0.41139   0.074076  0.5616    0.020386 -0.17742\n",
      "  0.89022   0.047395 -1.9203    0.45783   0.053517 -0.77082  -0.46773\n",
      " -0.62052  -0.98962   0.15288  -0.43882   1.1514    0.89418   0.58059\n",
      " -0.63541  -0.11832  -0.97754  -0.80708  -0.52732   0.11813   0.83627\n",
      "  1.4901  ]\n"
     ]
    }
   ],
   "source": [
    "print(glove[\"hello\"])\n",
    "print(glove[\"world\"])\n",
    "print(glove[\"arent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    x = []\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        word = re.sub(r'[^a-zA-Z]', \"\", word)\n",
    "        try:\n",
    "            x.append(glove[word])\n",
    "        except:\n",
    "            print()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.38497 ,  0.80092 ,  0.064106, -0.28355 , -0.026759, -0.34532 ,\n",
       "        -0.64253 , -0.11729 , -0.33257 ,  0.55243 , -0.087813,  0.9035  ,\n",
       "         0.47102 ,  0.56657 ,  0.6985  , -0.35229 , -0.86542 ,  0.90573 ,\n",
       "         0.03576 , -0.071705, -0.12327 ,  0.54923 ,  0.47005 ,  0.35572 ,\n",
       "         1.2611  , -0.67581 , -0.94983 ,  0.68666 ,  0.3871  , -1.3492  ,\n",
       "         0.63512 ,  0.46416 , -0.48814 ,  0.83827 , -0.9246  , -0.33722 ,\n",
       "         0.53741 , -1.0616  , -0.081403, -0.67111 ,  0.30923 , -0.3923  ,\n",
       "        -0.55002 , -0.68827 ,  0.58049 , -0.11626 ,  0.013139, -0.57654 ,\n",
       "         0.048833,  0.67204 ], dtype=float32),\n",
       " array([-0.41486 ,  0.71848 , -0.3045  ,  0.87445 ,  0.22441 , -0.56488 ,\n",
       "        -0.37566 , -0.44801 ,  0.61347 , -0.11359 ,  0.74556 , -0.10598 ,\n",
       "        -1.1882  ,  0.50974 ,  1.3511  ,  0.069851,  0.73314 ,  0.26773 ,\n",
       "        -1.1787  , -0.148   ,  0.039853,  0.033107, -0.27406 ,  0.25125 ,\n",
       "         0.41507 , -1.6188  , -0.81778 , -0.73892 , -0.28997 ,  0.57277 ,\n",
       "         3.4719  ,  0.73817 , -0.044495, -0.15119 , -0.93503 , -0.13152 ,\n",
       "        -0.28562 ,  0.76327 , -0.83332 , -0.6793  , -0.39099 , -0.64466 ,\n",
       "         1.0044  , -0.2051  ,  0.46799 ,  0.99314 , -0.16221 , -0.46022 ,\n",
       "        -0.37639 , -0.67542 ], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(50, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sentence, pad):\n",
    "    encoded_sample_pred_text = encode(sample_pred_text)\n",
    "    print(encoded_sample_pred_text)\n",
    "    print(\"len: \"+str(len(encoded_sample_pred_text)))\n",
    "    print(\"shape: \"+str(encoded_sample_pred_text[0].shape))\n",
    "#     encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "    print(\"Encodedsamplepredtext shape: \"+str(encoded_sample_pred_text)) # shape is (19,50)\n",
    "    predictions = model.predict(encoded_sample_pred_text) # This is definitely where it fails and no one knows why\n",
    "    print(predictions)\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
      "      dtype=float32), array([ 0.30824 ,  0.17223 , -0.23339 ,  0.023105,  0.28522 ,  0.23076 ,\n",
      "       -0.41048 , -1.0035  , -0.2072  ,  1.4327  , -0.80684 ,  0.68954 ,\n",
      "       -0.43648 ,  1.1069  ,  1.6107  , -0.31966 ,  0.47744 ,  0.79395 ,\n",
      "       -0.84374 ,  0.064509,  0.90251 ,  0.78609 ,  0.29699 ,  0.76057 ,\n",
      "        0.433   , -1.5032  , -1.6423  ,  0.30256 ,  0.30771 , -0.87057 ,\n",
      "        2.4782  , -0.025852,  0.5013  , -0.38593 , -0.15633 ,  0.45522 ,\n",
      "        0.04901 , -0.42599 , -0.86402 , -1.3076  , -0.29576 ,  1.209   ,\n",
      "       -0.3127  , -0.72462 , -0.80801 ,  0.082667,  0.26738 , -0.98177 ,\n",
      "       -0.32147 ,  0.99823 ], dtype=float32), array([ 0.086888, -0.19416 , -0.24267 , -0.33391 ,  0.56731 ,  0.39783 ,\n",
      "       -0.97809 ,  0.03159 , -0.61469 , -0.31406 ,  0.56145 ,  0.12886 ,\n",
      "       -0.84193 , -0.46992 ,  0.47097 ,  0.023012, -0.59609 ,  0.22291 ,\n",
      "       -1.1614  ,  0.3865  ,  0.067412,  0.44883 ,  0.17394 , -0.53574 ,\n",
      "        0.17909 , -2.1647  , -0.12827 ,  0.29036 , -0.15061 ,  0.35242 ,\n",
      "        3.124   , -0.90085 , -0.02567 , -0.41709 ,  0.40565 , -0.22703 ,\n",
      "        0.76829 ,  0.60982 ,  0.070068, -0.13271 , -0.1201  ,  0.096132,\n",
      "       -0.43998 , -0.48531 , -0.5188  , -0.3077  , -0.75028 , -0.77    ,\n",
      "        0.3945  , -0.16937 ], dtype=float32), array([-0.65575 ,  0.45659 , -0.16748 , -0.58345 , -0.23073 , -0.78348 ,\n",
      "       -0.23166 , -0.022452, -0.57968 ,  0.526   , -0.2214  ,  0.17614 ,\n",
      "        0.46513 ,  0.79142 ,  0.017403,  1.0879  ,  0.24418 ,  0.27523 ,\n",
      "       -0.26452 , -1.0389  ,  0.014045,  0.68459 ,  0.98151 ,  0.21561 ,\n",
      "        0.36278 , -0.51819 , -0.40552 ,  1.349   ,  1.5399  ,  0.60541 ,\n",
      "        2.6604  ,  0.074535, -0.076292,  0.12501 , -0.026268,  0.16843 ,\n",
      "       -0.41844 ,  0.44505 ,  0.25033 , -1.1557  ,  0.24575 ,  0.41847 ,\n",
      "       -0.10633 , -0.28433 ,  0.51215 ,  0.51371 ,  0.53004 , -0.889   ,\n",
      "        0.054744,  0.78793 ], dtype=float32), array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
      "      dtype=float32), array([ 0.24967 , -1.1191  , -0.56549 ,  1.0342  ,  0.061597, -0.039153,\n",
      "       -0.21348 , -1.6882  , -0.31362 ,  0.9975  ,  0.40779 ,  0.33803 ,\n",
      "       -0.24746 ,  0.94855 ,  0.34214 , -0.2801  , -0.049876,  1.0883  ,\n",
      "       -0.63906 , -0.37137 ,  1.1539  ,  0.36245 , -0.26472 , -0.237   ,\n",
      "        0.078832,  0.073706, -1.3419  , -0.28168 , -0.6817  , -1.1032  ,\n",
      "        1.9981  , -0.32429 ,  0.34673 , -0.92143 , -0.54805 ,  1.0781  ,\n",
      "       -0.59448 ,  0.28468 , -0.61416 , -0.91918 ,  0.17211 ,  0.5415  ,\n",
      "       -0.81269 , -0.72839 , -0.43651 ,  0.036827,  1.2455  , -0.35172 ,\n",
      "       -0.98901 ,  0.5693  ], dtype=float32), array([ 0.26818 ,  0.14346 , -0.27877 ,  0.016257,  0.11384 ,  0.69923 ,\n",
      "       -0.51332 , -0.47368 , -0.33075 , -0.13834 ,  0.2702  ,  0.30938 ,\n",
      "       -0.45012 , -0.4127  , -0.09932 ,  0.038085,  0.029749,  0.10076 ,\n",
      "       -0.25058 , -0.51818 ,  0.34558 ,  0.44922 ,  0.48791 , -0.080866,\n",
      "       -0.10121 , -1.3777  , -0.10866 , -0.23201 ,  0.012839, -0.46508 ,\n",
      "        3.8463  ,  0.31362 ,  0.13643 , -0.52244 ,  0.3302  ,  0.33707 ,\n",
      "       -0.35601 ,  0.32431 ,  0.12041 ,  0.3512  , -0.069043,  0.36885 ,\n",
      "        0.25168 , -0.24517 ,  0.25381 ,  0.1367  , -0.31178 , -0.6321  ,\n",
      "       -0.25028 , -0.38097 ], dtype=float32), array([ 4.1800e-01,  2.4968e-01, -4.1242e-01,  1.2170e-01,  3.4527e-01,\n",
      "       -4.4457e-02, -4.9688e-01, -1.7862e-01, -6.6023e-04, -6.5660e-01,\n",
      "        2.7843e-01, -1.4767e-01, -5.5677e-01,  1.4658e-01, -9.5095e-03,\n",
      "        1.1658e-02,  1.0204e-01, -1.2792e-01, -8.4430e-01, -1.2181e-01,\n",
      "       -1.6801e-02, -3.3279e-01, -1.5520e-01, -2.3131e-01, -1.9181e-01,\n",
      "       -1.8823e+00, -7.6746e-01,  9.9051e-02, -4.2125e-01, -1.9526e-01,\n",
      "        4.0071e+00, -1.8594e-01, -5.2287e-01, -3.1681e-01,  5.9213e-04,\n",
      "        7.4449e-03,  1.7778e-01, -1.5897e-01,  1.2041e-02, -5.4223e-02,\n",
      "       -2.9871e-01, -1.5749e-01, -3.4758e-01, -4.5637e-02, -4.4251e-01,\n",
      "        1.8785e-01,  2.7849e-03, -1.8411e-01, -1.1514e-01, -7.8581e-01],\n",
      "      dtype=float32), array([-0.039968, -0.048762,  1.2246  ,  1.466   , -0.17796 , -1.1676  ,\n",
      "       -0.10839 , -1.9967  , -0.92577 ,  0.23371 , -0.48908 ,  0.018957,\n",
      "        0.28537 ,  0.2265  ,  0.16274 , -0.38171 , -1.6703  ,  0.41664 ,\n",
      "        0.32512 , -1.4052  ,  0.44574 , -0.22046 , -0.13763 , -0.099371,\n",
      "        0.42012 ,  0.59221 , -0.56891 , -0.10839 ,  0.27664 , -0.31243 ,\n",
      "        2.4181  , -0.47577 , -0.030073, -1.4708  , -0.026761,  1.1806  ,\n",
      "       -0.037709,  0.50163 , -1.0283  , -1.1009  ,  1.4751  ,  0.3695  ,\n",
      "       -0.11994 , -0.30909 ,  0.20326 ,  0.93519 ,  1.4612  ,  0.26033 ,\n",
      "        0.172   ,  1.0076  ], dtype=float32), array([ 0.73363 , -0.74815 ,  0.45913 , -0.56041 ,  0.091855,  0.33015 ,\n",
      "       -1.2034  , -0.15565 , -1.1205  , -0.5938  ,  0.23299 , -0.46278 ,\n",
      "       -0.34786 , -0.47901 ,  0.57621 , -0.16053 , -0.26457 , -0.13732 ,\n",
      "       -0.91878 , -0.65339 ,  0.05884 ,  0.61553 ,  1.2607  , -0.39821 ,\n",
      "       -0.26056 , -1.0127  , -0.38517 , -0.096929, -0.11701 , -0.48536 ,\n",
      "        3.6902  ,  0.30744 ,  0.50713 , -0.6537  ,  0.80491 ,  0.23672 ,\n",
      "        0.61769 ,  0.030195, -0.57645 ,  0.60467 , -0.63949 , -0.11373 ,\n",
      "        0.84984 ,  0.41409 ,  0.083774, -0.28737 , -1.4735  , -0.20095 ,\n",
      "       -0.17246 , -1.0984  ], dtype=float32), array([ 3.2112e-01, -6.9306e-01,  4.7922e-01, -5.4602e-01,  2.8352e-01,\n",
      "        2.0346e-01, -9.8445e-01, -1.4103e-01, -1.3147e-01, -8.5975e-02,\n",
      "       -4.9509e-01,  2.7600e-03, -1.1173e+00,  3.3729e-01,  6.1312e-01,\n",
      "       -6.7110e-02,  3.5380e-01, -3.5183e-01, -5.8191e-01, -6.9525e-01,\n",
      "       -2.5032e-02,  6.1675e-01,  7.8522e-01, -1.9594e-01,  2.6324e-01,\n",
      "       -1.8976e+00,  1.4645e-01,  4.8885e-01,  6.1818e-01, -1.0120e+00,\n",
      "        3.7285e+00,  6.6615e-01, -3.3364e-01,  3.1896e-01, -1.5174e-01,\n",
      "        3.0980e-01,  4.9670e-02,  2.7144e-01,  3.4595e-01, -8.1850e-02,\n",
      "       -3.7469e-01,  3.9981e-01,  8.4925e-02,  3.1237e-01, -1.2677e-01,\n",
      "        3.6322e-02, -6.9533e-02, -4.3547e-01, -1.1080e-01, -5.8500e-01],\n",
      "      dtype=float32), array([ 0.70853  ,  0.57088  , -0.4716   ,  0.18048  ,  0.54449  ,\n",
      "        0.72603  ,  0.18157  , -0.52393  ,  0.10381  , -0.17566  ,\n",
      "        0.078852 , -0.36216  , -0.11829  , -0.83336  ,  0.11917  ,\n",
      "       -0.16605  ,  0.061555 , -0.012719 , -0.56623  ,  0.013616 ,\n",
      "        0.22851  , -0.14396  , -0.067549 , -0.38157  , -0.23698  ,\n",
      "       -1.7037   , -0.86692  , -0.26704  , -0.2589   ,  0.1767   ,\n",
      "        3.8676   , -0.1613   , -0.13273  , -0.68881  ,  0.18444  ,\n",
      "        0.0052464, -0.33874  , -0.078956 ,  0.24185  ,  0.36576  ,\n",
      "       -0.34727  ,  0.28483  ,  0.075693 , -0.062178 , -0.38988  ,\n",
      "        0.22902  , -0.21617  , -0.22562  , -0.093918 , -0.80375  ],\n",
      "      dtype=float32), array([ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
      "        2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
      "       -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
      "        3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
      "       -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
      "       -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
      "        4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
      "       -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
      "       -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
      "        2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01],\n",
      "      dtype=float32), array([-0.41486 ,  0.71848 , -0.3045  ,  0.87445 ,  0.22441 , -0.56488 ,\n",
      "       -0.37566 , -0.44801 ,  0.61347 , -0.11359 ,  0.74556 , -0.10598 ,\n",
      "       -1.1882  ,  0.50974 ,  1.3511  ,  0.069851,  0.73314 ,  0.26773 ,\n",
      "       -1.1787  , -0.148   ,  0.039853,  0.033107, -0.27406 ,  0.25125 ,\n",
      "        0.41507 , -1.6188  , -0.81778 , -0.73892 , -0.28997 ,  0.57277 ,\n",
      "        3.4719  ,  0.73817 , -0.044495, -0.15119 , -0.93503 , -0.13152 ,\n",
      "       -0.28562 ,  0.76327 , -0.83332 , -0.6793  , -0.39099 , -0.64466 ,\n",
      "        1.0044  , -0.2051  ,  0.46799 ,  0.99314 , -0.16221 , -0.46022 ,\n",
      "       -0.37639 , -0.67542 ], dtype=float32), array([ 1.1891e-01,  1.5255e-01, -8.2073e-02, -7.4144e-01,  7.5917e-01,\n",
      "       -4.8328e-01, -3.1009e-01,  5.1476e-01, -9.8708e-01,  6.1757e-04,\n",
      "       -1.5043e-01,  8.3770e-01, -1.0797e+00, -5.1460e-01,  1.3188e+00,\n",
      "        6.2007e-01,  1.3779e-01,  4.7108e-01, -7.2874e-02, -7.2675e-01,\n",
      "       -7.4116e-01,  7.5263e-01,  8.8180e-01,  2.9561e-01,  1.3548e+00,\n",
      "       -2.5701e+00, -1.3523e+00,  4.5880e-01,  1.0068e+00, -1.1856e+00,\n",
      "        3.4737e+00,  7.7898e-01, -7.2929e-01,  2.5102e-01, -2.6156e-01,\n",
      "       -3.4684e-01,  5.5841e-01,  7.5098e-01,  4.9830e-01, -2.6823e-01,\n",
      "       -2.7443e-03, -1.8298e-02, -2.8096e-01,  5.5318e-01,  3.7706e-02,\n",
      "        1.8555e-01, -1.5025e-01, -5.7512e-01, -2.6671e-01,  9.2121e-01],\n",
      "      dtype=float32), array([ 0.7619   , -0.29773  ,  0.51396  , -0.13303  ,  0.24156  ,\n",
      "        0.066799 , -0.54084  ,  0.2071   , -0.28225  , -0.11638  ,\n",
      "        0.21666  ,  0.54908  , -0.36744  , -0.10543  ,  0.81567  ,\n",
      "        1.1743   ,  0.56055  , -0.3345   ,  0.099767 , -0.87465  ,\n",
      "        0.12229  , -0.18532  ,  0.086783 , -0.36343  ,  0.008002 ,\n",
      "       -2.2268   , -0.20079  , -0.10313  ,  0.24318  , -0.39819  ,\n",
      "        3.7136   ,  0.59088  , -1.1013   , -0.25292  ,  0.0057067,\n",
      "       -0.60475  ,  0.35965  , -0.059581 , -0.029059 , -0.3989   ,\n",
      "       -0.52631  ,  0.12436  ,  0.13609  ,  0.12699  , -0.23032  ,\n",
      "       -0.044567 , -0.6545   ,  0.43088  , -0.22768  ,  0.4026   ],\n",
      "      dtype=float32), array([ 0.52735 , -0.61475 , -0.42524 , -0.88306 , -0.15339 , -0.21839 ,\n",
      "        0.31857 ,  0.093879,  0.34386 , -0.032786, -0.29509 ,  0.49267 ,\n",
      "        0.47724 ,  0.27872 ,  0.5514  ,  0.68597 ,  0.064149, -0.63731 ,\n",
      "        0.75359 , -1.2377  ,  0.58236 , -0.14113 ,  0.42288 , -0.10094 ,\n",
      "       -0.45307 , -1.0228  ,  0.084672, -0.42117 , -0.43834 , -0.21805 ,\n",
      "        1.6802  ,  0.45255 , -1.1585  , -0.43177 ,  0.53736 , -0.45175 ,\n",
      "        0.86718 ,  0.42056 ,  0.14023 , -0.3656  , -0.26819 , -0.15519 ,\n",
      "        0.49592 ,  0.91899 ,  0.73838 , -0.051499,  0.19389 ,  1.1663  ,\n",
      "       -0.10517 ,  1.2007  ], dtype=float32), array([ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
      "        2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
      "       -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
      "        3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
      "       -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
      "       -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
      "        4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
      "       -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
      "       -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
      "        2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01],\n",
      "      dtype=float32), array([ 0.30824 ,  0.17223 , -0.23339 ,  0.023105,  0.28522 ,  0.23076 ,\n",
      "       -0.41048 , -1.0035  , -0.2072  ,  1.4327  , -0.80684 ,  0.68954 ,\n",
      "       -0.43648 ,  1.1069  ,  1.6107  , -0.31966 ,  0.47744 ,  0.79395 ,\n",
      "       -0.84374 ,  0.064509,  0.90251 ,  0.78609 ,  0.29699 ,  0.76057 ,\n",
      "        0.433   , -1.5032  , -1.6423  ,  0.30256 ,  0.30771 , -0.87057 ,\n",
      "        2.4782  , -0.025852,  0.5013  , -0.38593 , -0.15633 ,  0.45522 ,\n",
      "        0.04901 , -0.42599 , -0.86402 , -1.3076  , -0.29576 ,  1.209   ,\n",
      "       -0.3127  , -0.72462 , -0.80801 ,  0.082667,  0.26738 , -0.98177 ,\n",
      "       -0.32147 ,  0.99823 ], dtype=float32)]\n",
      "len: 19\n",
      "shape: (50,)\n",
      "Encodedsamplepredtext shape: tf.Tensor(\n",
      "[[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      "  -1.1514e-01 -7.8581e-01]\n",
      " [ 3.0824e-01  1.7223e-01 -2.3339e-01  2.3105e-02  2.8522e-01  2.3076e-01\n",
      "  -4.1048e-01 -1.0035e+00 -2.0720e-01  1.4327e+00 -8.0684e-01  6.8954e-01\n",
      "  -4.3648e-01  1.1069e+00  1.6107e+00 -3.1966e-01  4.7744e-01  7.9395e-01\n",
      "  -8.4374e-01  6.4509e-02  9.0251e-01  7.8609e-01  2.9699e-01  7.6057e-01\n",
      "   4.3300e-01 -1.5032e+00 -1.6423e+00  3.0256e-01  3.0771e-01 -8.7057e-01\n",
      "   2.4782e+00 -2.5852e-02  5.0130e-01 -3.8593e-01 -1.5633e-01  4.5522e-01\n",
      "   4.9010e-02 -4.2599e-01 -8.6402e-01 -1.3076e+00 -2.9576e-01  1.2090e+00\n",
      "  -3.1270e-01 -7.2462e-01 -8.0801e-01  8.2667e-02  2.6738e-01 -9.8177e-01\n",
      "  -3.2147e-01  9.9823e-01]\n",
      " [ 8.6888e-02 -1.9416e-01 -2.4267e-01 -3.3391e-01  5.6731e-01  3.9783e-01\n",
      "  -9.7809e-01  3.1590e-02 -6.1469e-01 -3.1406e-01  5.6145e-01  1.2886e-01\n",
      "  -8.4193e-01 -4.6992e-01  4.7097e-01  2.3012e-02 -5.9609e-01  2.2291e-01\n",
      "  -1.1614e+00  3.8650e-01  6.7412e-02  4.4883e-01  1.7394e-01 -5.3574e-01\n",
      "   1.7909e-01 -2.1647e+00 -1.2827e-01  2.9036e-01 -1.5061e-01  3.5242e-01\n",
      "   3.1240e+00 -9.0085e-01 -2.5670e-02 -4.1709e-01  4.0565e-01 -2.2703e-01\n",
      "   7.6829e-01  6.0982e-01  7.0068e-02 -1.3271e-01 -1.2010e-01  9.6132e-02\n",
      "  -4.3998e-01 -4.8531e-01 -5.1880e-01 -3.0770e-01 -7.5028e-01 -7.7000e-01\n",
      "   3.9450e-01 -1.6937e-01]\n",
      " [-6.5575e-01  4.5659e-01 -1.6748e-01 -5.8345e-01 -2.3073e-01 -7.8348e-01\n",
      "  -2.3166e-01 -2.2452e-02 -5.7968e-01  5.2600e-01 -2.2140e-01  1.7614e-01\n",
      "   4.6513e-01  7.9142e-01  1.7403e-02  1.0879e+00  2.4418e-01  2.7523e-01\n",
      "  -2.6452e-01 -1.0389e+00  1.4045e-02  6.8459e-01  9.8151e-01  2.1561e-01\n",
      "   3.6278e-01 -5.1819e-01 -4.0552e-01  1.3490e+00  1.5399e+00  6.0541e-01\n",
      "   2.6604e+00  7.4535e-02 -7.6292e-02  1.2501e-01 -2.6268e-02  1.6843e-01\n",
      "  -4.1844e-01  4.4505e-01  2.5033e-01 -1.1557e+00  2.4575e-01  4.1847e-01\n",
      "  -1.0633e-01 -2.8433e-01  5.1215e-01  5.1371e-01  5.3004e-01 -8.8900e-01\n",
      "   5.4744e-02  7.8793e-01]\n",
      " [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      "  -1.1514e-01 -7.8581e-01]\n",
      " [ 2.4967e-01 -1.1191e+00 -5.6549e-01  1.0342e+00  6.1597e-02 -3.9153e-02\n",
      "  -2.1348e-01 -1.6882e+00 -3.1362e-01  9.9750e-01  4.0779e-01  3.3803e-01\n",
      "  -2.4746e-01  9.4855e-01  3.4214e-01 -2.8010e-01 -4.9876e-02  1.0883e+00\n",
      "  -6.3906e-01 -3.7137e-01  1.1539e+00  3.6245e-01 -2.6472e-01 -2.3700e-01\n",
      "   7.8832e-02  7.3706e-02 -1.3419e+00 -2.8168e-01 -6.8170e-01 -1.1032e+00\n",
      "   1.9981e+00 -3.2429e-01  3.4673e-01 -9.2143e-01 -5.4805e-01  1.0781e+00\n",
      "  -5.9448e-01  2.8468e-01 -6.1416e-01 -9.1918e-01  1.7211e-01  5.4150e-01\n",
      "  -8.1269e-01 -7.2839e-01 -4.3651e-01  3.6827e-02  1.2455e+00 -3.5172e-01\n",
      "  -9.8901e-01  5.6930e-01]\n",
      " [ 2.6818e-01  1.4346e-01 -2.7877e-01  1.6257e-02  1.1384e-01  6.9923e-01\n",
      "  -5.1332e-01 -4.7368e-01 -3.3075e-01 -1.3834e-01  2.7020e-01  3.0938e-01\n",
      "  -4.5012e-01 -4.1270e-01 -9.9320e-02  3.8085e-02  2.9749e-02  1.0076e-01\n",
      "  -2.5058e-01 -5.1818e-01  3.4558e-01  4.4922e-01  4.8791e-01 -8.0866e-02\n",
      "  -1.0121e-01 -1.3777e+00 -1.0866e-01 -2.3201e-01  1.2839e-02 -4.6508e-01\n",
      "   3.8463e+00  3.1362e-01  1.3643e-01 -5.2244e-01  3.3020e-01  3.3707e-01\n",
      "  -3.5601e-01  3.2431e-01  1.2041e-01  3.5120e-01 -6.9043e-02  3.6885e-01\n",
      "   2.5168e-01 -2.4517e-01  2.5381e-01  1.3670e-01 -3.1178e-01 -6.3210e-01\n",
      "  -2.5028e-01 -3.8097e-01]\n",
      " [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
      "  -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
      "  -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
      "  -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
      "  -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
      "   4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
      "   1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
      "  -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
      "  -1.1514e-01 -7.8581e-01]\n",
      " [-3.9968e-02 -4.8762e-02  1.2246e+00  1.4660e+00 -1.7796e-01 -1.1676e+00\n",
      "  -1.0839e-01 -1.9967e+00 -9.2577e-01  2.3371e-01 -4.8908e-01  1.8957e-02\n",
      "   2.8537e-01  2.2650e-01  1.6274e-01 -3.8171e-01 -1.6703e+00  4.1664e-01\n",
      "   3.2512e-01 -1.4052e+00  4.4574e-01 -2.2046e-01 -1.3763e-01 -9.9371e-02\n",
      "   4.2012e-01  5.9221e-01 -5.6891e-01 -1.0839e-01  2.7664e-01 -3.1243e-01\n",
      "   2.4181e+00 -4.7577e-01 -3.0073e-02 -1.4708e+00 -2.6761e-02  1.1806e+00\n",
      "  -3.7709e-02  5.0163e-01 -1.0283e+00 -1.1009e+00  1.4751e+00  3.6950e-01\n",
      "  -1.1994e-01 -3.0909e-01  2.0326e-01  9.3519e-01  1.4612e+00  2.6033e-01\n",
      "   1.7200e-01  1.0076e+00]\n",
      " [ 7.3363e-01 -7.4815e-01  4.5913e-01 -5.6041e-01  9.1855e-02  3.3015e-01\n",
      "  -1.2034e+00 -1.5565e-01 -1.1205e+00 -5.9380e-01  2.3299e-01 -4.6278e-01\n",
      "  -3.4786e-01 -4.7901e-01  5.7621e-01 -1.6053e-01 -2.6457e-01 -1.3732e-01\n",
      "  -9.1878e-01 -6.5339e-01  5.8840e-02  6.1553e-01  1.2607e+00 -3.9821e-01\n",
      "  -2.6056e-01 -1.0127e+00 -3.8517e-01 -9.6929e-02 -1.1701e-01 -4.8536e-01\n",
      "   3.6902e+00  3.0744e-01  5.0713e-01 -6.5370e-01  8.0491e-01  2.3672e-01\n",
      "   6.1769e-01  3.0195e-02 -5.7645e-01  6.0467e-01 -6.3949e-01 -1.1373e-01\n",
      "   8.4984e-01  4.1409e-01  8.3774e-02 -2.8737e-01 -1.4735e+00 -2.0095e-01\n",
      "  -1.7246e-01 -1.0984e+00]\n",
      " [ 3.2112e-01 -6.9306e-01  4.7922e-01 -5.4602e-01  2.8352e-01  2.0346e-01\n",
      "  -9.8445e-01 -1.4103e-01 -1.3147e-01 -8.5975e-02 -4.9509e-01  2.7600e-03\n",
      "  -1.1173e+00  3.3729e-01  6.1312e-01 -6.7110e-02  3.5380e-01 -3.5183e-01\n",
      "  -5.8191e-01 -6.9525e-01 -2.5032e-02  6.1675e-01  7.8522e-01 -1.9594e-01\n",
      "   2.6324e-01 -1.8976e+00  1.4645e-01  4.8885e-01  6.1818e-01 -1.0120e+00\n",
      "   3.7285e+00  6.6615e-01 -3.3364e-01  3.1896e-01 -1.5174e-01  3.0980e-01\n",
      "   4.9670e-02  2.7144e-01  3.4595e-01 -8.1850e-02 -3.7469e-01  3.9981e-01\n",
      "   8.4925e-02  3.1237e-01 -1.2677e-01  3.6322e-02 -6.9533e-02 -4.3547e-01\n",
      "  -1.1080e-01 -5.8500e-01]\n",
      " [ 7.0853e-01  5.7088e-01 -4.7160e-01  1.8048e-01  5.4449e-01  7.2603e-01\n",
      "   1.8157e-01 -5.2393e-01  1.0381e-01 -1.7566e-01  7.8852e-02 -3.6216e-01\n",
      "  -1.1829e-01 -8.3336e-01  1.1917e-01 -1.6605e-01  6.1555e-02 -1.2719e-02\n",
      "  -5.6623e-01  1.3616e-02  2.2851e-01 -1.4396e-01 -6.7549e-02 -3.8157e-01\n",
      "  -2.3698e-01 -1.7037e+00 -8.6692e-01 -2.6704e-01 -2.5890e-01  1.7670e-01\n",
      "   3.8676e+00 -1.6130e-01 -1.3273e-01 -6.8881e-01  1.8444e-01  5.2464e-03\n",
      "  -3.3874e-01 -7.8956e-02  2.4185e-01  3.6576e-01 -3.4727e-01  2.8483e-01\n",
      "   7.5693e-02 -6.2178e-02 -3.8988e-01  2.2902e-01 -2.1617e-01 -2.2562e-01\n",
      "  -9.3918e-02 -8.0375e-01]\n",
      " [ 5.3074e-01  4.0117e-01 -4.0785e-01  1.5444e-01  4.7782e-01  2.0754e-01\n",
      "  -2.6951e-01 -3.4023e-01 -1.0879e-01  1.0563e-01 -1.0289e-01  1.0849e-01\n",
      "  -4.9681e-01 -2.5128e-01  8.4025e-01  3.8949e-01  3.2284e-01 -2.2797e-01\n",
      "  -4.4342e-01 -3.1649e-01 -1.2406e-01 -2.8170e-01  1.9467e-01  5.5513e-02\n",
      "   5.6705e-01 -1.7419e+00 -9.1145e-01  2.7036e-01  4.1927e-01  2.0279e-02\n",
      "   4.0405e+00 -2.4943e-01 -2.0416e-01 -6.2762e-01 -5.4783e-02 -2.6883e-01\n",
      "   1.8444e-01  1.8204e-01 -2.3536e-01 -1.6155e-01 -2.7655e-01  3.5506e-02\n",
      "  -3.8211e-01 -7.5134e-04 -2.4822e-01  2.8164e-01  1.2819e-01  2.8762e-01\n",
      "   1.4440e-01  2.3611e-01]\n",
      " [-4.1486e-01  7.1848e-01 -3.0450e-01  8.7445e-01  2.2441e-01 -5.6488e-01\n",
      "  -3.7566e-01 -4.4801e-01  6.1347e-01 -1.1359e-01  7.4556e-01 -1.0598e-01\n",
      "  -1.1882e+00  5.0974e-01  1.3511e+00  6.9851e-02  7.3314e-01  2.6773e-01\n",
      "  -1.1787e+00 -1.4800e-01  3.9853e-02  3.3107e-02 -2.7406e-01  2.5125e-01\n",
      "   4.1507e-01 -1.6188e+00 -8.1778e-01 -7.3892e-01 -2.8997e-01  5.7277e-01\n",
      "   3.4719e+00  7.3817e-01 -4.4495e-02 -1.5119e-01 -9.3503e-01 -1.3152e-01\n",
      "  -2.8562e-01  7.6327e-01 -8.3332e-01 -6.7930e-01 -3.9099e-01 -6.4466e-01\n",
      "   1.0044e+00 -2.0510e-01  4.6799e-01  9.9314e-01 -1.6221e-01 -4.6022e-01\n",
      "  -3.7639e-01 -6.7542e-01]\n",
      " [ 1.1891e-01  1.5255e-01 -8.2073e-02 -7.4144e-01  7.5917e-01 -4.8328e-01\n",
      "  -3.1009e-01  5.1476e-01 -9.8708e-01  6.1757e-04 -1.5043e-01  8.3770e-01\n",
      "  -1.0797e+00 -5.1460e-01  1.3188e+00  6.2007e-01  1.3779e-01  4.7108e-01\n",
      "  -7.2874e-02 -7.2675e-01 -7.4116e-01  7.5263e-01  8.8180e-01  2.9561e-01\n",
      "   1.3548e+00 -2.5701e+00 -1.3523e+00  4.5880e-01  1.0068e+00 -1.1856e+00\n",
      "   3.4737e+00  7.7898e-01 -7.2929e-01  2.5102e-01 -2.6156e-01 -3.4684e-01\n",
      "   5.5841e-01  7.5098e-01  4.9830e-01 -2.6823e-01 -2.7443e-03 -1.8298e-02\n",
      "  -2.8096e-01  5.5318e-01  3.7706e-02  1.8555e-01 -1.5025e-01 -5.7512e-01\n",
      "  -2.6671e-01  9.2121e-01]\n",
      " [ 7.6190e-01 -2.9773e-01  5.1396e-01 -1.3303e-01  2.4156e-01  6.6799e-02\n",
      "  -5.4084e-01  2.0710e-01 -2.8225e-01 -1.1638e-01  2.1666e-01  5.4908e-01\n",
      "  -3.6744e-01 -1.0543e-01  8.1567e-01  1.1743e+00  5.6055e-01 -3.3450e-01\n",
      "   9.9767e-02 -8.7465e-01  1.2229e-01 -1.8532e-01  8.6783e-02 -3.6343e-01\n",
      "   8.0020e-03 -2.2268e+00 -2.0079e-01 -1.0313e-01  2.4318e-01 -3.9819e-01\n",
      "   3.7136e+00  5.9088e-01 -1.1013e+00 -2.5292e-01  5.7067e-03 -6.0475e-01\n",
      "   3.5965e-01 -5.9581e-02 -2.9059e-02 -3.9890e-01 -5.2631e-01  1.2436e-01\n",
      "   1.3609e-01  1.2699e-01 -2.3032e-01 -4.4567e-02 -6.5450e-01  4.3088e-01\n",
      "  -2.2768e-01  4.0260e-01]\n",
      " [ 5.2735e-01 -6.1475e-01 -4.2524e-01 -8.8306e-01 -1.5339e-01 -2.1839e-01\n",
      "   3.1857e-01  9.3879e-02  3.4386e-01 -3.2786e-02 -2.9509e-01  4.9267e-01\n",
      "   4.7724e-01  2.7872e-01  5.5140e-01  6.8597e-01  6.4149e-02 -6.3731e-01\n",
      "   7.5359e-01 -1.2377e+00  5.8236e-01 -1.4113e-01  4.2288e-01 -1.0094e-01\n",
      "  -4.5307e-01 -1.0228e+00  8.4672e-02 -4.2117e-01 -4.3834e-01 -2.1805e-01\n",
      "   1.6802e+00  4.5255e-01 -1.1585e+00 -4.3177e-01  5.3736e-01 -4.5175e-01\n",
      "   8.6718e-01  4.2056e-01  1.4023e-01 -3.6560e-01 -2.6819e-01 -1.5519e-01\n",
      "   4.9592e-01  9.1899e-01  7.3838e-01 -5.1499e-02  1.9389e-01  1.1663e+00\n",
      "  -1.0517e-01  1.2007e+00]\n",
      " [ 5.3074e-01  4.0117e-01 -4.0785e-01  1.5444e-01  4.7782e-01  2.0754e-01\n",
      "  -2.6951e-01 -3.4023e-01 -1.0879e-01  1.0563e-01 -1.0289e-01  1.0849e-01\n",
      "  -4.9681e-01 -2.5128e-01  8.4025e-01  3.8949e-01  3.2284e-01 -2.2797e-01\n",
      "  -4.4342e-01 -3.1649e-01 -1.2406e-01 -2.8170e-01  1.9467e-01  5.5513e-02\n",
      "   5.6705e-01 -1.7419e+00 -9.1145e-01  2.7036e-01  4.1927e-01  2.0279e-02\n",
      "   4.0405e+00 -2.4943e-01 -2.0416e-01 -6.2762e-01 -5.4783e-02 -2.6883e-01\n",
      "   1.8444e-01  1.8204e-01 -2.3536e-01 -1.6155e-01 -2.7655e-01  3.5506e-02\n",
      "  -3.8211e-01 -7.5134e-04 -2.4822e-01  2.8164e-01  1.2819e-01  2.8762e-01\n",
      "   1.4440e-01  2.3611e-01]\n",
      " [ 3.0824e-01  1.7223e-01 -2.3339e-01  2.3105e-02  2.8522e-01  2.3076e-01\n",
      "  -4.1048e-01 -1.0035e+00 -2.0720e-01  1.4327e+00 -8.0684e-01  6.8954e-01\n",
      "  -4.3648e-01  1.1069e+00  1.6107e+00 -3.1966e-01  4.7744e-01  7.9395e-01\n",
      "  -8.4374e-01  6.4509e-02  9.0251e-01  7.8609e-01  2.9699e-01  7.6057e-01\n",
      "   4.3300e-01 -1.5032e+00 -1.6423e+00  3.0256e-01  3.0771e-01 -8.7057e-01\n",
      "   2.4782e+00 -2.5852e-02  5.0130e-01 -3.8593e-01 -1.5633e-01  4.5522e-01\n",
      "   4.9010e-02 -4.2599e-01 -8.6402e-01 -1.3076e+00 -2.9576e-01  1.2090e+00\n",
      "  -3.1270e-01 -7.2462e-01 -8.0801e-01  8.2667e-02  2.6738e-01 -9.8177e-01\n",
      "  -3.2147e-01  9.9823e-01]], shape=(19, 50), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-9a93ddfc56eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_pred_text = ('The movie was cool. The animation and the graphics '\n\u001b[1;32m      2\u001b[0m                     'were out of this world. I would recommend this movie.')\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_pred_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-d60bad26a805>\u001b[0m in \u001b[0;36msample_predict\u001b[0;34m(sentence, pad)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mencoded_sample_pred_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sample_pred_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encodedsamplepredtext shape: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sample_pred_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shape is (19,50)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_sample_pred_text\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is definitely where it fails and no one knows why\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    397\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2620\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m       \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2622\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2623\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dict_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m   2707\u001b[0m           \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2709\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2710\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2711\u001b[0m         \u001b[0;31m# This Model or a submodel is dynamic and hasn't overridden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 812\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    813\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 50]"
     ]
    }
   ],
   "source": [
    "sample_pred_text = ('The movie was cool. The animation and the graphics '\n",
    "                    'were out of this world. I would recommend this movie.')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8185\n"
     ]
    }
   ],
   "source": [
    "encoder = info.features['text'].encoder\n",
    "print ('Vocabulary size: {}'.format(encoder.vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 ----> The \n",
      "27 ----> movie \n",
      "18 ----> was \n",
      "2724 ----> cool\n",
      "3 ----> . \n",
      "19 ----> The \n",
      "206 ----> and\n",
      "7137 ----> rew\n",
      "7961 ---->  \n",
      "6562 ----> seven \n",
      "7381 ----> yan\n",
      "291 ----> g \n",
      "6366 ----> loser\n",
      "7961 ---->  \n",
      "6408 ----> mous\n",
      "49 ----> e \n",
      "786 ----> gi\n",
      "670 ----> ra\n",
      "3053 ----> ffe\n",
      "7961 ---->  \n",
      "1270 ----> ze\n",
      "1861 ----> bra\n",
      "7961 ---->  \n",
      "1143 ----> au\n",
      "8029 ----> d\n",
      "8031 ----> f\n",
      "3898 ----> sf\n",
      "1761 ----> ds\n",
      "7386 ----> ston\n",
      "795 ----> om\n",
      "339 ----> ous \n",
      "2972 ----> pie\n"
     ]
    }
   ],
   "source": [
    "encoded_string = encoder.encode('The movie was cool. The andrew seven yang loser mouse giraffe zebra audfsfdsstonomous pie')\n",
    "for index in encoded_string:\n",
    "    print('{} ----> {}'.format(index, encoder.decode([index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n",
    "\n",
    "test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec, size):\n",
    "    zeros = [0] * (size - len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sentence, pad):\n",
    "    encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "    if pad:\n",
    "        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "    predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.200e+01 1.290e+02 5.834e+03 1.250e+02 7.996e+03 3.000e+00 3.778e+03\n",
      " 7.961e+03 9.000e+00 8.100e+01 2.724e+03], shape=(11,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.200e+01 1.290e+02 5.834e+03 1.250e+02 7.996e+03 3.000e+00 3.778e+03\n",
      "  7.961e+03 9.000e+00 8.100e+01 2.724e+03]], shape=(1, 11), dtype=float32)\n",
      "[[0.5018966]]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_pred_text = ('I think Alexander C. Sun is really cool')\n",
    "predictions = sample_predict(sample_pred_text, pad=False)\n",
    "print (predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
