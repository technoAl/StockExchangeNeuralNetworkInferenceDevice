{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for i in range(14,32):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(file.name)\n",
    "    except:\n",
    "        continue\n",
    "for i in range(1,20):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "    except:\n",
    "        continue\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700,)\n",
      "(2700,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100, 1)            301       \n",
      "=================================================================\n",
      "Total params: 15,000,301\n",
      "Trainable params: 15,000,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras import layers\n",
    "x_train = np.array(a, dtype=np.str)\n",
    "x_train = x_train.astype(str)\n",
    "print(x_train.shape)\n",
    "y_train = np.zeros(2700)+0.314159\n",
    "print(y_train.shape)\n",
    "import tensorflow as tf\n",
    "embed_size = 300     # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "# model1.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "# model1.add(GlobalMaxPool1D())\n",
    "# model1.add(Dropout(0.2))\n",
    "# model1.add(Dense(64, activation='relu'))\n",
    "# model1.add(Dropout(0.2))\n",
    "# model1.add(Dense(32, activation='relu'))\n",
    "# model1.add(Dropout(0.2))\n",
    "model1.add(Dense(1,activation='sigmoid'))\n",
    "model1.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(100), metrics=['accuracy'])\n",
    "model1.summary()\n",
    "x_trainR = np.array(x_train)[:2200]\n",
    "y_trainR = np.array(y_train)[:2200]\n",
    "x_test = np.array(x_train)[2200:]\n",
    "y_test = np.array(y_train)[2200:]\n",
    "x_train = x_trainR\n",
    "y_train = y_trainR\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2200 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "2200/2200 [==============================] - 2s 907us/sample - loss: 0.3193 - accuracy: 0.0000e+00 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "2200/2200 [==============================] - 2s 832us/sample - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "2200/2200 [==============================] - 2s 815us/sample - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "2200/2200 [==============================] - 2s 853us/sample - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "2200/2200 [==============================] - 2s 842us/sample - loss: 0.3343 - accuracy: 0.0000e+00 - val_loss: 0.3341 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x635dc3a58>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train, y_train, epochs=5, batch_size=220, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_size(vec, size):\n",
    "    zeros = [0] * (size - len(vec))\n",
    "    vec.extend(zeros)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predict(sentence, pad):\n",
    "    encoded_sample_pred_text = encoder.encode(sample_pred_text)\n",
    "\n",
    "    if pad:\n",
    "        encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n",
    "    encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n",
    "    predictions = model1.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n",
    "\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding_3/embeddings:0' shape=(50000, 300) dtype=float32, numpy=\n",
      "array([[ 3.0912701e-02, -4.9593560e-03,  4.7769498e-02, ...,\n",
      "         3.3881117e-02, -1.8121220e-02,  3.1104807e-02],\n",
      "       [-5.9883809e+00,  5.9588203e+00, -5.2675862e+00, ...,\n",
      "        -5.9337935e+00,  5.8765602e+00, -6.0302949e+00],\n",
      "       [-4.3353953e+00,  5.9822183e+00,  5.9377379e+00, ...,\n",
      "        -5.9468856e+00,  5.9439125e+00, -6.0289674e+00],\n",
      "       ...,\n",
      "       [ 1.0547243e-02, -2.5794411e-02, -4.8193559e-03, ...,\n",
      "         6.1958805e-03, -2.4530161e-02,  2.4477128e-02],\n",
      "       [-4.2608131e-02, -6.2674060e-03, -8.6550117e-03, ...,\n",
      "         4.8036385e-02,  4.5751706e-03, -1.1925053e-02],\n",
      "       [ 4.9055029e-02, -3.3342648e-02,  8.9760050e-03, ...,\n",
      "         1.8299889e-02, -5.1050894e-03, -2.7315808e-02]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[ 2.5315142 ,  0.6627123 ,  3.336858  , ...,  2.4928002 ,\n",
      "        -1.1379876 , -5.139054  ],\n",
      "       [ 2.6342227 ,  2.28176   ,  3.1209383 , ..., -3.0682576 ,\n",
      "        -0.24565811, -1.5029749 ],\n",
      "       [ 2.6644893 , -0.6422555 ,  4.8627057 , ...,  0.5134005 ,\n",
      "        -2.9763434 ,  2.8640797 ],\n",
      "       ...,\n",
      "       [-0.19244772, -3.6466012 , -2.4144576 , ..., -3.8041644 ,\n",
      "         0.26417318,  5.0698686 ],\n",
      "       [-3.230993  ,  4.1188645 ,  2.8944807 , ..., -3.0811388 ,\n",
      "        -2.8583431 , -5.0211773 ],\n",
      "       [-2.295336  ,  3.9140005 , -1.755903  , ...,  4.5377603 ,\n",
      "        -3.688132  ,  4.4425473 ]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[ 2.3824327 , -2.6245599 ,  0.4004619 , ...,  0.9336105 ,\n",
      "         0.3440935 , -4.522273  ],\n",
      "       [ 1.3412768 , -3.7256837 ,  3.829265  , ..., -3.1293046 ,\n",
      "         1.2806718 ,  3.2151573 ],\n",
      "       [ 2.0591145 ,  0.3255259 , -3.5305996 , ...,  0.6230376 ,\n",
      "         0.91796553, -3.9143174 ],\n",
      "       ...,\n",
      "       [-2.7464807 , -3.2880497 , -2.584528  , ..., -3.6534848 ,\n",
      "        -0.44841325, -0.83135396],\n",
      "       [ 1.6776376 , -1.6121521 ,  1.8808017 , ..., -0.13940455,\n",
      "         0.34083992,  3.8680725 ],\n",
      "       [ 0.23789965,  3.9296176 ,  3.2759678 , ...,  2.5451703 ,\n",
      "        -0.29377642, -4.7246394 ]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([ 5.8798423, -5.9608493, -5.979438 , -5.929815 ,  5.947189 ,\n",
      "        5.927596 , -5.293123 , -5.923426 ,  5.9471703,  5.9393992,\n",
      "       -5.9737   , -5.9804387,  5.9416246, -5.955041 , -5.245368 ,\n",
      "       -5.8408246,  5.7587256,  5.9834685,  5.9094424,  5.956105 ,\n",
      "       -5.9498925,  5.98265  ,  5.9030185, -5.8462653,  5.842051 ,\n",
      "        5.90963  , -5.9167633,  4.405011 , -5.968618 ,  5.9328856,\n",
      "        4.070488 ,  5.8639627,  5.2583256,  5.8706594,  5.9785504,\n",
      "        4.670446 , -5.972698 , -5.954889 , -5.9304876, -5.972936 ,\n",
      "       -5.9519134,  5.9563704,  5.9582667, -5.7187285, -4.765073 ,\n",
      "        5.9440837,  5.6791234, -5.9498487, -5.8266673,  5.8604074,\n",
      "       -5.9746637,  5.8052306, -5.926845 , -5.9362707, -5.921596 ,\n",
      "       -5.952486 ,  5.968442 ,  5.9496684, -5.9719796, -5.765172 ,\n",
      "       -5.8306136,  5.0431585,  5.962414 ,  5.9712405,  5.9716835,\n",
      "        5.922027 , -5.8835783, -5.9507756, -5.9749665,  5.946701 ,\n",
      "       -5.9057875,  5.2178683, -5.8380647, -5.9743667,  5.936738 ,\n",
      "        5.6645627, -5.970372 , -5.792296 ,  5.8374743,  5.8121815,\n",
      "       -5.9520197,  5.963998 , -5.9256377, -5.94552  ,  5.9010086,\n",
      "       -5.893935 ,  5.874779 , -5.897638 ,  5.9631047,  5.953458 ,\n",
      "       -5.9517107,  5.863292 ,  5.9696813, -5.7396216, -5.939962 ,\n",
      "       -5.57224  ,  5.94869  ,  5.935193 ,  5.937909 , -5.9140873,\n",
      "       -5.982216 ,  5.9030194, -5.9448824, -5.9640336, -5.935456 ,\n",
      "       -5.920868 , -5.6370487, -5.970024 , -5.8285694,  5.831419 ,\n",
      "        5.9650936, -5.972701 , -5.9602   ,  5.808977 , -5.9480443,\n",
      "        5.7869883,  5.902571 , -5.9342756, -5.9210863, -5.9589314,\n",
      "       -5.9710155, -5.9378233, -5.844849 , -5.908834 , -5.987609 ,\n",
      "       -5.919305 ,  5.684831 , -5.9845295,  6.756507 , -4.916873 ,\n",
      "       -4.93892  , -4.570027 ,  6.889627 ,  6.8550844, -4.2918396,\n",
      "       -4.860815 ,  6.922225 ,  6.9223747, -4.949681 , -4.962357 ,\n",
      "        6.4781513, -4.941783 , -4.001497 , -4.104517 ,  6.4430585,\n",
      "        6.9779577,  6.907124 ,  6.9163823, -4.939099 ,  6.9641185,\n",
      "       -3.3683465, -4.858695 ,  6.8610497,  6.844536 , -4.858879 ,\n",
      "        6.5647936, -4.9411583,  6.812045 , -2.7399685,  6.484116 ,\n",
      "        6.470397 ,  6.8785214,  6.95776  ,  4.75862  , -4.9541173,\n",
      "       -4.884678 , -4.9161663, -4.9374084, -4.889487 ,  6.7137866,\n",
      "        6.91419  , -4.6949987, -4.1888924,  6.8815684,  6.5346813,\n",
      "       -4.9024596, -4.796575 , -4.1828456, -4.9550295,  6.6796045,\n",
      "       -4.890382 , -4.889786 , -4.865367 , -4.910058 ,  6.8989472,\n",
      "        6.872434 , -4.9542513, -2.8960085, -4.706692 ,  3.8397875,\n",
      "        6.913994 ,  6.944337 ,  6.8904824,  6.911192 , -4.847078 ,\n",
      "       -4.933347 , -4.952594 ,  6.88622  , -4.7613955,  5.7829084,\n",
      "       -4.4054804, -4.932133 ,  6.8952065,  5.4177847, -4.9160933,\n",
      "        4.893722 ,  6.7819266,  6.892489 , -4.2517686,  6.920891 ,\n",
      "       -4.88006  , -4.926642 ,  6.7623844, -4.891082 ,  6.7964454,\n",
      "       -4.8066897,  6.9395523,  6.9171753, -4.885967 ,  6.765436 ,\n",
      "        6.913935 , -3.4505303, -4.860829 ,  6.4294868,  6.9316926,\n",
      "        6.856931 ,  6.908666 , -4.8943577, -4.962053 ,  6.828411 ,\n",
      "       -4.8469124, -4.847795 , -4.8632774, -4.8906364, -4.6911473,\n",
      "       -4.8867164, -4.665165 ,  6.4773493,  6.950966 , -4.946569 ,\n",
      "       -4.932662 ,  6.155682 , -4.926567 ,  6.5785704,  6.8390164,\n",
      "       -4.894701 , -4.506513 , -4.9114423, -4.89311  , -4.79272  ,\n",
      "       -4.8649106, -4.8575997, -4.939713 , -4.85215  , -1.6841881,\n",
      "       -4.9657598,  6.0047812, -6.0051384, -6.0052485, -6.0049114,\n",
      "        6.003968 ,  6.004199 ,  6.0039144, -6.0049534,  6.005105 ,\n",
      "        6.004933 , -6.005151 , -6.0047116,  6.0048122, -6.0050335,\n",
      "        6.0007596, -6.004554 ,  6.0046945,  6.0051765,  6.004841 ,\n",
      "        6.0051584, -6.0044484,  6.00513  ,  6.004701 ,  6.005033 ,\n",
      "        6.0023723, -6.002424 ,  5.9025908, -6.0045676, -6.0052447,\n",
      "        6.0048513, -6.001183 ,  6.004611 , -5.9722424,  6.0044723,\n",
      "        6.0049763, -5.9946103, -6.005012 , -6.005165 , -6.0044303,\n",
      "       -6.00509  , -6.0049744,  6.0052257,  6.0046124,  5.9991126,\n",
      "        6.004672 ,  6.0051684,  6.0043635, -6.004897 , -6.0029573,\n",
      "        6.004741 , -6.004975 ,  6.005026 ,  5.9960947, -6.004571 ,\n",
      "       -6.004526 , -6.0049834,  6.00502  ,  6.0052166, -6.004543 ,\n",
      "       -6.002955 , -6.00047  , -6.0045114,  6.004995 ,  6.00521  ,\n",
      "        6.005224 ,  6.0048413, -6.0046186, -6.0050654, -6.00488  ,\n",
      "        6.0051117, -6.0037203, -6.003479 , -6.002284 , -6.0052867,\n",
      "        6.004318 ,  6.0021653, -6.005261 , -6.004936 ,  5.984611 ,\n",
      "        6.004641 , -6.005214 ,  6.0050573, -6.0048623, -6.004975 ,\n",
      "        6.003332 , -6.004687 ,  6.0046034, -6.005102 ,  6.004391 ,\n",
      "        6.004584 , -6.004224 , -6.0037146,  6.005189 ,  6.0040555,\n",
      "       -6.0044537, -6.00459  ,  6.004379 ,  6.00423  ,  6.0051394,\n",
      "       -5.823132 , -6.0052557, -6.003681 , -6.003641 , -6.0043454,\n",
      "       -5.9995193,  5.9869585,  6.0027685, -6.004929 , -6.0048404,\n",
      "        6.0033946,  6.005059 , -6.005168 , -6.00489  ,  6.004899 ,\n",
      "       -6.0043736,  6.0049534,  6.0037503, -6.004484 ,  5.977317 ,\n",
      "       -6.0051465, -6.0050387, -6.004364 , -6.005013 , -6.004915 ,\n",
      "       -6.005349 ,  6.0022016, -5.99772  , -6.005264 ,  5.8803244,\n",
      "       -5.960348 , -5.9796996, -5.9286127,  5.947613 ,  5.9285684,\n",
      "       -5.2939816, -5.9229045,  5.946504 ,  5.940187 , -5.9735527,\n",
      "       -5.98038  ,  5.9412694, -5.955458 , -5.230694 , -5.8392086,\n",
      "        5.75646  ,  5.983582 ,  5.909348 ,  5.9568405, -5.950748 ,\n",
      "        5.9827256,  5.904901 , -5.8458533,  5.843087 ,  5.9092627,\n",
      "       -5.91711  ,  4.4187927, -5.9684305,  5.933477 ,  4.1851106,\n",
      "        5.863689 ,  5.2121778,  5.869241 ,  5.9786725,  4.665914 ,\n",
      "       -5.972751 , -5.9551744, -5.9296594, -5.9728146, -5.9524837,\n",
      "        5.95629  ,  5.9591575, -5.726393 , -4.7328553,  5.9437704,\n",
      "        5.6811566, -5.950063 , -5.824439 ,  5.863011 , -5.9745083,\n",
      "        5.8042493, -5.927747 , -5.936328 , -5.9221826, -5.9526415,\n",
      "        5.9681516,  5.9495645, -5.972022 , -5.769226 , -5.8273664,\n",
      "        5.051786 ,  5.9626093,  5.971272 ,  5.9713774,  5.92232  ,\n",
      "       -5.883719 , -5.950994 , -5.974553 ,  5.9460745, -5.9072948,\n",
      "        5.2129827, -5.8384333, -5.9749665,  5.9371424,  5.6580696,\n",
      "       -5.9705176, -5.7881527,  5.8395844,  5.8102317, -5.9516654,\n",
      "        5.9634767, -5.9261527, -5.9459724,  5.90218  , -5.892404 ,\n",
      "        5.8760133, -5.8959837,  5.963291 ,  5.952576 , -5.951809 ,\n",
      "        5.8637977,  5.969329 , -5.7445884, -5.941087 , -5.5811343,\n",
      "        5.949629 ,  5.9358444,  5.937737 , -5.9144993, -5.982136 ,\n",
      "        5.9027624, -5.9448953, -5.9643946, -5.9351153, -5.9203787,\n",
      "       -5.6560535, -5.9698367, -5.82766  ,  5.8308744,  5.9656096,\n",
      "       -5.9727325, -5.960392 ,  5.8119035, -5.9481215,  5.7878823,\n",
      "        5.898406 , -5.9340773, -5.9211206, -5.9588647, -5.9710236,\n",
      "       -5.938142 , -5.845967 , -5.909596 , -5.9876027, -5.920667 ,\n",
      "        5.6907544, -5.984499 ], dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[ 3.9684837 , -3.2086203 , -1.3172015 , ..., -2.2051377 ,\n",
      "        -3.5058844 , -0.336764  ],\n",
      "       [-0.8275023 , -2.4504282 ,  2.6468346 , ..., -3.501638  ,\n",
      "        -2.5434446 , -2.0105925 ],\n",
      "       [ 2.0021257 ,  2.9710748 , -3.7639542 , ...,  2.1935155 ,\n",
      "         3.9208415 ,  0.28418794],\n",
      "       ...,\n",
      "       [ 0.39998782,  3.9641094 , -0.26555896, ...,  2.7466316 ,\n",
      "        -3.701022  , -2.8361256 ],\n",
      "       [ 2.668071  ,  3.246484  , -2.2003317 , ..., -2.5906458 ,\n",
      "        -2.905074  , -1.5942005 ],\n",
      "       [ 1.3920554 , -1.9720026 , -3.160408  , ...,  2.7856877 ,\n",
      "        -2.6487148 , -3.6030421 ]], dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[-0.4421013 , -0.42903614,  1.4424918 , ...,  0.09474854,\n",
      "         0.9813143 , -1.0405476 ],\n",
      "       [-0.29486465,  3.2930222 ,  0.20807886, ..., -1.1239738 ,\n",
      "        -1.8324752 , -1.9280177 ],\n",
      "       [-0.4386591 , -1.6429788 ,  3.4823086 , ...,  1.7404137 ,\n",
      "        -1.4338129 , -0.89296454],\n",
      "       ...,\n",
      "       [ 0.5765244 , -2.0455449 ,  2.5170968 , ..., -0.85352415,\n",
      "        -2.6020381 , -0.33266965],\n",
      "       [-1.4577338 , -2.4833057 , -1.5453609 , ...,  1.0100825 ,\n",
      "        -2.9590988 ,  1.7338018 ],\n",
      "       [-0.89558583,  2.4394317 ,  2.3313243 , ..., -0.26961154,\n",
      "        -2.511595  , -2.1473858 ]], dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([ 5.8897157 ,  5.9296365 ,  5.967876  ,  5.9625874 ,  5.961374  ,\n",
      "        5.962863  , -5.860697  ,  5.872979  , -5.923474  ,  5.9298787 ,\n",
      "        5.5243664 , -4.2099977 ,  5.852295  ,  5.9340844 ,  5.8405433 ,\n",
      "       -5.9398627 ,  5.9035306 , -5.975494  , -5.6611204 ,  5.220307  ,\n",
      "        5.832558  , -5.874933  ,  5.9200354 , -5.9723845 , -3.7100685 ,\n",
      "        5.96925   , -5.34129   , -5.907304  ,  5.9647365 , -5.977169  ,\n",
      "       -5.9706936 , -5.7817297 ,  5.9729347 ,  5.9577756 ,  5.879708  ,\n",
      "       -5.97258   , -5.9807525 ,  4.8158965 , -4.5846305 , -5.960436  ,\n",
      "        5.947295  , -5.9806414 ,  5.955147  , -5.9502993 ,  5.9053216 ,\n",
      "       -5.9152846 , -4.7697353 , -5.8690796 , -5.9667892 ,  5.834262  ,\n",
      "       -5.919765  ,  5.785179  ,  5.9087296 ,  5.980173  , -5.852092  ,\n",
      "        5.7539525 ,  4.223893  , -5.945815  , -5.9435577 ,  5.7772727 ,\n",
      "        5.069643  , -5.974913  ,  4.0262837 ,  4.8597074 ,  5.8430734 ,\n",
      "       -5.9452677 ,  5.8547916 , -5.533956  , -5.892534  , -5.917592  ,\n",
      "       -5.879562  , -5.9697733 , -5.9321785 , -5.852299  , -5.91511   ,\n",
      "       -5.9773455 , -5.618912  , -5.9120135 , -5.801755  ,  5.908679  ,\n",
      "       -5.9013968 , -5.9123416 , -5.714575  ,  5.890306  ,  5.948382  ,\n",
      "       -5.9540696 ,  5.957579  , -5.945447  , -5.926232  , -5.8951664 ,\n",
      "       -5.9778094 ,  5.956103  ,  5.970211  ,  5.4041686 , -5.9598784 ,\n",
      "        5.02209   , -5.5015125 , -5.9827213 ,  5.9021473 , -5.929382  ,\n",
      "        5.9415708 ,  5.9778852 , -5.9743195 , -5.903348  ,  5.91615   ,\n",
      "       -5.9735484 , -5.970039  ,  5.928494  , -5.952487  , -5.9827533 ,\n",
      "       -5.967982  ,  5.870621  , -5.9143543 ,  4.862533  ,  5.9536147 ,\n",
      "       -5.5486274 , -5.9151125 , -5.8635516 , -5.9769278 , -5.933061  ,\n",
      "        5.9156146 , -5.9443645 ,  5.879346  , -5.92687   , -5.9451127 ,\n",
      "       -5.6689487 , -5.9373236 , -5.6536503 ,  6.703298  ,  6.9123826 ,\n",
      "        6.916007  ,  6.9269586 ,  6.9561596 ,  6.8979154 , -4.8150005 ,\n",
      "        5.2575245 , -4.798378  ,  6.871187  ,  6.58972   , -4.4702525 ,\n",
      "        6.8389497 ,  6.0984874 ,  6.7481494 , -4.7728653 ,  6.821112  ,\n",
      "       -4.9480205 , -4.549796  ,  6.0038247 , -2.0621498 , -4.583692  ,\n",
      "        6.789747  , -4.937285  , -4.2551394 ,  6.8701196 , -3.9224238 ,\n",
      "       -4.856239  ,  6.9206424 , -4.8451366 , -4.9560585 ,  6.7387567 ,\n",
      "        6.945114  ,  6.8975563 ,  6.8291616 , -4.9462276 , -4.970252  ,\n",
      "       -4.645584  , -4.7138057 , -4.9278316 ,  6.770969  , -4.8884    ,\n",
      "        6.9174232 , -4.8689976 ,  6.756027  , -4.590351  , -4.6204753 ,\n",
      "       -4.8112    , -4.8631287 ,  3.161941  , -4.849172  , -2.6854284 ,\n",
      "        6.7461786 ,  6.968756  , -4.680107  ,  6.6509495 ,  6.762649  ,\n",
      "       -4.8590236 , -4.903065  ,  6.8422804 ,  3.967636  , -4.9552774 ,\n",
      "       -4.7457733 , -4.452241  ,  6.7016444 , -4.8794665 ,  6.688184  ,\n",
      "       -0.77756834, -4.8520784 , -3.6978881 , -3.2077687 , -4.859886  ,\n",
      "       -4.8616605 ,  6.038339  ,  6.1849895 , -4.9659758 , -4.558311  ,\n",
      "       -4.895065  , -4.689862  ,  6.8515925 , -4.819663  ,  5.5942206 ,\n",
      "       -2.9459598 ,  6.8058996 ,  6.8730354 , -4.872982  ,  6.9260755 ,\n",
      "       -4.9143667 , -4.782664  , -4.8830633 , -4.9427834 ,  6.8654213 ,\n",
      "        6.885363  , -4.3293576 , -4.8808236 , -1.8144038 , -4.3162937 ,\n",
      "       -4.9430027 ,  6.8245206 , -4.828614  ,  6.870941  ,  6.9637446 ,\n",
      "       -4.9416614 , -4.7811284 ,  6.8198986 , -4.9417634 , -4.943458  ,\n",
      "        6.849912  , -4.9315667 , -4.9698043 , -4.949913  , -2.5486574 ,\n",
      "       -4.8690214 , -1.6204373 ,  6.904781  , -4.239817  , -4.857785  ,\n",
      "       -4.714856  , -4.862214  , -4.9145947 ,  6.8647294 , -4.8331923 ,\n",
      "        6.6040297 , -4.8761134 , -4.8846273 , -4.3474407 , -4.8623843 ,\n",
      "       -4.806644  , -5.988282  ,  6.0045514 ,  6.0043674 ,  6.0050435 ,\n",
      "        6.0049295 ,  6.005096  ,  6.0046816 ,  6.004874  , -6.00497   ,\n",
      "        6.0040555 , -6.004245  , -6.0028224 ,  5.9831085 ,  6.004867  ,\n",
      "        6.0047383 , -6.0047398 ,  6.004121  , -6.0050797 , -6.003845  ,\n",
      "        6.002207  ,  6.003456  , -6.0040784 ,  6.0025353 , -6.0047183 ,\n",
      "       -5.98023   ,  6.004926  , -6.004537  , -6.0044594 ,  6.0050573 ,\n",
      "       -6.0052404 , -6.0046754 , -6.0050764 ,  6.005099  ,  6.0047216 ,\n",
      "        6.0044394 , -6.0050993 , -6.005107  , -6.004493  , -6.0044975 ,\n",
      "       -6.005081  ,  6.003563  , -6.0052485 ,  6.0051455 , -6.0050545 ,\n",
      "       -6.000698  , -6.003959  ,  6.004988  ,  6.004408  , -6.0051064 ,\n",
      "        6.003869  , -6.000389  , -6.000557  ,  6.004061  ,  6.0052333 ,\n",
      "       -6.0033402 ,  6.004454  , -6.002192  , -6.005101  , -6.0045657 ,\n",
      "        6.003661  ,  6.0006533 , -6.0043635 ,  6.0046444 , -5.9989233 ,\n",
      "        6.00453   , -6.004566  ,  6.0030303 ,  6.0030627 , -6.0040593 ,\n",
      "       -6.001954  , -5.991069  , -6.0052457 ,  5.990644  , -6.005135  ,\n",
      "       -6.005112  , -6.005099  , -6.002139  , -6.004395  ,  6.003502  ,\n",
      "        6.004742  , -6.0029    , -6.00476   , -6.0043817 ,  6.000668  ,\n",
      "        6.004907  , -6.0050325 ,  6.0049825 , -6.0048127 , -6.0033264 ,\n",
      "       -6.0049806 , -6.005015  ,  6.004626  ,  6.004932  ,  6.003779  ,\n",
      "       -6.0050545 ,  6.0033274 , -6.0024114 , -6.0047655 ,  6.0033607 ,\n",
      "       -6.003324  ,  6.0049872 ,  6.004929  , -6.0051665 ,  6.0040817 ,\n",
      "        6.003955  , -6.005136  , -6.0049872 ,  5.999536  , -6.0048394 ,\n",
      "       -6.005268  , -6.0046573 ,  6.004606  ,  6.00471   , -6.003269  ,\n",
      "        6.005204  ,  6.004166  ,  6.0041394 , -6.003308  , -6.0050726 ,\n",
      "       -6.004738  ,  6.0042152 , -6.0050116 ,  6.004131  , -6.0034842 ,\n",
      "       -6.0043964 , -6.004847  , -6.0049024 ,  5.9976764 ,  5.887475  ,\n",
      "        5.92873   ,  5.9675593 ,  5.9622054 ,  5.9614353 ,  5.963313  ,\n",
      "       -5.8609548 ,  5.8730655 , -5.924196  ,  5.9310317 ,  5.529442  ,\n",
      "       -4.408086  ,  5.852657  ,  5.933353  ,  5.8397555 , -5.940988  ,\n",
      "        5.904211  , -5.9755764 , -5.650889  ,  5.263839  ,  5.8313336 ,\n",
      "       -5.8735485 ,  5.920975  , -5.9724326 , -3.5164697 ,  5.969521  ,\n",
      "       -5.3862066 , -5.906656  ,  5.9649324 , -5.9769125 , -5.9710774 ,\n",
      "       -5.782975  ,  5.9730954 ,  5.9577203 ,  5.8801694 , -5.9730067 ,\n",
      "       -5.9808216 ,  4.9856424 , -4.3621883 , -5.960756  ,  5.9478555 ,\n",
      "       -5.980452  ,  5.954957  , -5.9503    ,  5.9047055 , -5.9160357 ,\n",
      "       -4.825129  , -5.8709073 , -5.9665565 ,  5.838306  , -5.9213934 ,\n",
      "        5.782293  ,  5.9088335 ,  5.980392  , -5.848605  ,  5.751839  ,\n",
      "        4.304696  , -5.944705  , -5.9438977 ,  5.780386  ,  5.0912113 ,\n",
      "       -5.974622  ,  3.9010339 ,  4.9213924 ,  5.843598  , -5.945921  ,\n",
      "        5.853312  , -5.544267  , -5.8925133 , -5.9172134 , -5.881265  ,\n",
      "       -5.969939  , -5.932233  , -5.8441277 , -5.9154797 , -5.977506  ,\n",
      "       -5.6205935 , -5.911352  , -5.801119  ,  5.909548  , -5.9018793 ,\n",
      "       -5.9124713 , -5.7136602 ,  5.8904552 ,  5.9481673 , -5.953846  ,\n",
      "        5.957332  , -5.9454236 , -5.926594  , -5.8942685 , -5.977947  ,\n",
      "        5.9560423 ,  5.9700766 ,  5.40963   , -5.9595995 ,  5.0556974 ,\n",
      "       -5.5129094 , -5.9827967 ,  5.902296  , -5.929643  ,  5.9416513 ,\n",
      "        5.977632  , -5.974608  , -5.9033065 ,  5.916817  , -5.9734397 ,\n",
      "       -5.970311  ,  5.928673  , -5.952142  , -5.9826803 , -5.9678073 ,\n",
      "        5.8741517 , -5.9141464 ,  4.902391  ,  5.954032  , -5.5439816 ,\n",
      "       -5.9142556 , -5.8661222 , -5.9766498 , -5.9346256 ,  5.9165816 ,\n",
      "       -5.9444313 ,  5.880639  , -5.9274116 , -5.94574   , -5.670068  ,\n",
      "       -5.937134  , -5.64203   ], dtype=float32)>, <tf.Variable 'dense_9/kernel:0' shape=(256, 64) dtype=float32, numpy=\n",
      "array([[-6.0693126,  5.7399316,  5.835967 , ..., -6.0818176,  5.9870124,\n",
      "         6.0668707],\n",
      "       [-6.0369215,  5.808433 ,  5.857092 , ..., -6.0542746,  5.886422 ,\n",
      "         6.0061917],\n",
      "       [-5.9873033,  5.7670336,  6.0981045, ..., -5.8684964,  6.0291233,\n",
      "         5.9520874],\n",
      "       ...,\n",
      "       [-5.9375296,  5.4835362,  6.045732 , ..., -5.985347 ,  5.971762 ,\n",
      "         6.06504  ],\n",
      "       [-5.989032 ,  5.3671107,  5.954495 , ..., -5.842526 ,  5.932569 ,\n",
      "         5.98656  ],\n",
      "       [-5.976629 , -5.6385574, -5.4846363, ..., -6.012702 ,  5.8291774,\n",
      "         6.123916 ]], dtype=float32)>, <tf.Variable 'dense_9/bias:0' shape=(64,) dtype=float32, numpy=\n",
      "array([-6.005079 ,  6.000276 ,  6.0047684, -6.0048566, -6.0034695,\n",
      "        6.0052257, -5.9694653, -6.005186 ,  6.0042157, -6.005272 ,\n",
      "       -6.0051074,  6.0049195,  6.005233 , -6.0048757, -6.005019 ,\n",
      "        6.0049777, -6.004772 ,  6.005191 , -6.0047545,  6.005334 ,\n",
      "        6.004802 , -6.0043955,  6.0049243, -6.003916 ,  6.005209 ,\n",
      "        6.00453  ,  6.0048914, -6.0037847,  6.0053034, -6.004708 ,\n",
      "       -6.0048532,  6.0050526, -6.005318 , -6.005309 ,  6.005103 ,\n",
      "        6.005026 , -6.004692 , -6.005299 , -6.0047026,  6.002049 ,\n",
      "       -6.0047913,  6.004386 , -6.0049396, -6.0046926, -6.0051284,\n",
      "        6.0042863,  6.0051627,  6.0005774,  6.005221 , -6.003766 ,\n",
      "       -6.004663 ,  6.0049057,  5.9940295,  6.004729 , -6.0047917,\n",
      "        6.0049515, -6.005188 , -6.0049973,  6.005177 ,  6.004639 ,\n",
      "       -6.0052037, -6.0050106,  6.003709 ,  6.005201 ], dtype=float32)>, <tf.Variable 'dense_10/kernel:0' shape=(64, 32) dtype=float32, numpy=\n",
      "array([[-5.8288193, -6.233839 , -6.046815 , ..., -6.140033 ,  5.974311 ,\n",
      "        -6.0408936],\n",
      "       [-6.124728 , -5.949749 , -5.8507695, ..., -6.2395935,  5.933986 ,\n",
      "        -6.195593 ],\n",
      "       [ 6.148482 ,  5.915124 ,  6.076911 , ...,  6.1536765, -5.8307676,\n",
      "         5.7983317],\n",
      "       ...,\n",
      "       [ 5.9681787,  5.7944717,  5.8817406, ...,  6.0902677, -6.2233863,\n",
      "         5.798988 ],\n",
      "       [ 5.931565 ,  6.1354637,  6.076475 , ...,  6.0869474, -5.9590197,\n",
      "         5.925398 ],\n",
      "       [ 5.766572 ,  6.042315 ,  6.0858283, ...,  6.1536283, -5.8392377,\n",
      "         6.227283 ]], dtype=float32)>, <tf.Variable 'dense_10/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-6.005316 , -6.005111 , -6.0052595, -6.005191 , -6.004225 ,\n",
      "        6.005048 ,  6.0052667, -6.005215 , -6.005213 , -6.0053015,\n",
      "       -6.0052633,  6.0052605, -6.002515 , -6.0052595,  6.005302 ,\n",
      "        6.0051894,  6.0051875,  6.0047755, -6.0040503, -6.005185 ,\n",
      "        6.0049486,  6.005168 ,  6.0051246, -6.0021043, -6.005229 ,\n",
      "       -6.001084 ,  6.004054 ,  6.005322 ,  6.005317 , -6.0050797,\n",
      "        6.0050654, -6.005184 ], dtype=float32)>, <tf.Variable 'dense_11/kernel:0' shape=(32, 1) dtype=float32, numpy=\n",
      "array([[ 4.334146 ],\n",
      "       [ 6.5053525],\n",
      "       [ 1.5244318],\n",
      "       [ 1.9233407],\n",
      "       [ 8.06747  ],\n",
      "       [-4.1730695],\n",
      "       [-2.8970547],\n",
      "       [-2.6649578],\n",
      "       [ 3.7622907],\n",
      "       [ 2.802592 ],\n",
      "       [ 4.7195563],\n",
      "       [ 2.2718353],\n",
      "       [ 8.365947 ],\n",
      "       [ 3.8799095],\n",
      "       [-2.3743289],\n",
      "       [-4.2220454],\n",
      "       [-1.3107911],\n",
      "       [-6.3757052],\n",
      "       [ 1.5623796],\n",
      "       [ 7.2795672],\n",
      "       [ 3.4088387],\n",
      "       [-1.1719512],\n",
      "       [-3.3723528],\n",
      "       [ 7.0181746],\n",
      "       [ 0.9888998],\n",
      "       [ 3.6187303],\n",
      "       [-7.4524016],\n",
      "       [ 5.3223133],\n",
      "       [-7.225857 ],\n",
      "       [ 8.65582  ],\n",
      "       [-4.3968716],\n",
      "       [ 8.266707 ]], dtype=float32)>, <tf.Variable 'dense_11/bias:0' shape=(1,) dtype=float32, numpy=array([-5.3661604], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(x))\n",
    "    x =pad_sequences(tokenizer.texts_to_sequences(x), maxlen=maxlen)\n",
    "    return model1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUNK NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.99569923, -9.9946905 , -9.99459666, ...,  9.99647872,\n",
       "        9.99664191,  9.99740685])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.random.random(10000)*20-10\n",
    "x_train = np.sort(x_train)\n",
    "y_train = np.cos(x_train)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = tf.keras.Sequential()\n",
    "# model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "# model1.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model2.add(Dense(64, activation='relu', input_shape=(1,)))\n",
    "# model2.add(Dropout(0.2))\n",
    "# model2.add(Dense(32, activation='relu'))\n",
    "# model1.add(Dropout(0.2))\n",
    "model2.add(Dense(1))\n",
    "model2.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(1e), metrics=['accuracy'])\n",
    "model2.summary()\n",
    "x_trainR = np.array(x_train)[:8000]\n",
    "y_trainR = np.array(y_train)[:8000]\n",
    "x_test = np.array(x_train)[8000:]\n",
    "y_test = np.array(y_train)[8000:]\n",
    "x_train = x_trainR\n",
    "y_train = y_trainR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/1000\n",
      "8000/8000 [==============================] - 0s 51us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "8000/8000 [==============================] - 0s 21us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "8000/8000 [==============================] - 0s 22us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "8000/8000 [==============================] - 0s 24us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "8000/8000 [==============================] - 0s 25us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "8000/8000 [==============================] - 0s 23us/sample - loss: nan - accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "4416/8000 [===============>..............] - ETA: 0s - loss: nan - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0158cb3997e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \"\"\"\n\u001b[1;32m   1137\u001b[0m     return self._call_flat(\n\u001b[0;32m-> 1138\u001b[0;31m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0m\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mFlatten\u001b[0;34m(nested, expand_composites)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m     \"\"\"\n\u001b[0;32m-> 2651\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIsSequenceForData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.fit(x_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
