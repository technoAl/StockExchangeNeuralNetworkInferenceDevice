{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/19\n",
      "10/20\n",
      "10/26\n",
      "10/27\n",
      "11/2\n",
      "11/3\n",
      "11/9\n",
      "11/16\n",
      "11/17\n",
      "11/22\n",
      "11/23\n",
      "11/24\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File Reading\n",
    "\"\"\"\n",
    "a = []\n",
    "for i in range(14,31):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(file.name)\n",
    "    except:\n",
    "        print(\"10/\"+str(i))\n",
    "for i in range(1,30):\n",
    "    if i != 10:\n",
    "        try:\n",
    "            for j in range(100):\n",
    "                with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                    try:\n",
    "                        a.append(str(file.read()))\n",
    "                    except Exception as e:\n",
    "                        print(file.name)\n",
    "        except:\n",
    "            print(\"11/\"+str(i))\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700,)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 256)          439296    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 15,477,002\n",
      "Trainable params: 15,477,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural Network Model Creation\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "x_train = np.array(a, dtype=np.str)\n",
    "x_train = x_train.astype(str)\n",
    "# print(x_train.shape)\n",
    "y_train = np.zeros(2700)+0.9\n",
    "print(y_train.shape)\n",
    "import tensorflow as tf\n",
    "embed_size = 300 \n",
    "max_features = 50000 \n",
    "maxlen = 100\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "model1.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model1.add(GlobalMaxPool1D())\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(16, activation='relu'))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model1.summary()\n",
    "x_trainR = np.array(x_train)[:2200]\n",
    "y_trainR = np.array(y_train)[:2200]\n",
    "x_test = np.array(x_train)[2200:]\n",
    "y_test = np.array(y_train)[2200:]\n",
    "x_train = x_trainR\n",
    "y_train = y_trainR\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Formats data labels\n",
    "\"\"\"\n",
    "def toFinal(a):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > 0:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad: 10/19\n",
      "Bad: 10/20\n",
      "Bad: 10/23\n",
      "Bad: 10/25\n",
      "Bad: 10/26\n",
      "Bad: 10/27\n",
      "Bad: 11/2\n",
      "Bad: 11/3\n",
      "Bad: 11/9\n",
      "Bad: 11/10\n",
      "Bad: 11/16\n",
      "Bad: 11/17\n",
      "(2700,)\n",
      "(2200, 100)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads and formats data labels\n",
    "\"\"\"\n",
    "y_train = []\n",
    "for i in range(14,32):\n",
    "    try:\n",
    "        with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "            j = file.read().split(',')[1]\n",
    "            assert j is not None\n",
    "            j = j.replace('\\n','')\n",
    "            for _ in range(100):\n",
    "                y_train.append(float(j))\n",
    "    except:\n",
    "        print(\"Bad: 10/\"+str(i))\n",
    "for i in range(1,22):\n",
    "    try:\n",
    "        with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "            j = file.read().split(',')[1]\n",
    "            assert j is not None\n",
    "            j = j.replace('\\n','')\n",
    "            for _ in range(100):\n",
    "                y_train.append(float(j))\n",
    "    except:\n",
    "        print(\"Bad: 11/\"+str(i))\n",
    "toFinal(y_train)\n",
    "# print(y_train)\n",
    "y_train = np.array(y_train)\n",
    "# print(y_train)\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400\n",
      "2200\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y_train))\n",
    "print(y_train.size)\n",
    "y_train = y_train[:1500]\n",
    "x_train = x_train[:2200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples\n",
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 12s 8ms/sample - loss: 0.6929 - accuracy: 0.5333\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6911 - accuracy: 0.5333\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6896 - accuracy: 0.5333\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6884 - accuracy: 0.5333\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6852 - accuracy: 0.5287\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6797 - accuracy: 0.5520\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 11s 7ms/sample - loss: 0.6753 - accuracy: 0.5707\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6690 - accuracy: 0.5760\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6738 - accuracy: 0.5627\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6643 - accuracy: 0.5860\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6628 - accuracy: 0.5733\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6628 - accuracy: 0.5833\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 10s 6ms/sample - loss: 0.6574 - accuracy: 0.5833\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6577 - accuracy: 0.5867\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6553 - accuracy: 0.5820\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6513 - accuracy: 0.5920\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6518 - accuracy: 0.5813\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6465 - accuracy: 0.5887\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6442 - accuracy: 0.5913\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6434 - accuracy: 0.5900\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6434 - accuracy: 0.5947\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6425 - accuracy: 0.5947\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 10s 7ms/sample - loss: 0.6413 - accuracy: 0.5927\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6409 - accuracy: 0.5947\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6408 - accuracy: 0.5927\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 10s 7ms/sample - loss: 0.6424 - accuracy: 0.5980\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6404 - accuracy: 0.5913\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6405 - accuracy: 0.5967\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6403 - accuracy: 0.5947\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6396 - accuracy: 0.5967\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6407 - accuracy: 0.5927\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6390 - accuracy: 0.5953\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6406 - accuracy: 0.5953\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6401 - accuracy: 0.5907\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6393 - accuracy: 0.5973\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6391 - accuracy: 0.5933\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6399 - accuracy: 0.5967\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 10s 6ms/sample - loss: 0.6394 - accuracy: 0.5953\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6389 - accuracy: 0.5967\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6398 - accuracy: 0.5920\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6385 - accuracy: 0.5967\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6385 - accuracy: 0.5967\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6388 - accuracy: 0.5967\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6385 - accuracy: 0.5967\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6386 - accuracy: 0.5967\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6383 - accuracy: 0.5960\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6390 - accuracy: 0.5967\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6388 - accuracy: 0.5940\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6380 - accuracy: 0.5967\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6383 - accuracy: 0.5960\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6382 - accuracy: 0.5960\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6379 - accuracy: 0.5967\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 9s 6ms/sample - loss: 0.6390 - accuracy: 0.5953\n",
      "Epoch 54/200\n",
      "1300/1500 [=========================>....] - ETA: 1s - loss: 0.6383 - accuracy: 0.5900"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Trains Model\n",
    "\"\"\"\n",
    "history = model1.fit(x_train, y_train, epochs=200, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(x))\n",
    "    x =pad_sequences(tokenizer.texts_to_sequences(x), maxlen=maxlen)\n",
    "    return model1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding/embeddings:0' shape=(50000, 300) dtype=float32, numpy=\n",
      "array([[ 0.03498546, -0.01473368,  0.00580215, ...,  0.01270312,\n",
      "        -0.00630977, -0.05688262],\n",
      "       [ 0.00413679, -0.03184727, -0.04803321, ...,  0.01632361,\n",
      "         0.02689   , -0.05694659],\n",
      "       [ 0.0532416 ,  0.01232925, -0.04633527, ...,  0.00021526,\n",
      "        -0.01948338, -0.07421148],\n",
      "       ...,\n",
      "       [-0.04614413,  0.03991515,  0.0294464 , ..., -0.0416157 ,\n",
      "         0.00676612, -0.01475601],\n",
      "       [ 0.00618427,  0.0092067 ,  0.00890341, ..., -0.01048785,\n",
      "         0.02362057, -0.00103893],\n",
      "       [ 0.02417636, -0.0289183 ,  0.01927852, ...,  0.04732117,\n",
      "        -0.0267395 ,  0.04819292]], dtype=float32)>, <tf.Variable 'bidirectional/forward_lstm/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[ 0.12731835, -0.07421365, -0.09264964, ...,  0.06707245,\n",
      "         0.00698306, -0.04800601],\n",
      "       [-0.0887736 ,  0.03444036, -0.01086832, ...,  0.08801305,\n",
      "         0.01525536,  0.03890301],\n",
      "       [ 0.06643807,  0.05816736,  0.09534094, ...,  0.00247696,\n",
      "        -0.00518619,  0.11667562],\n",
      "       ...,\n",
      "       [-0.03300087,  0.03489426, -0.13954255, ...,  0.1165331 ,\n",
      "        -0.05213311, -0.02467555],\n",
      "       [-0.00938565, -0.09355447,  0.10588134, ..., -0.06723834,\n",
      "        -0.03080774,  0.03716535],\n",
      "       [ 0.05018937,  0.11017876,  0.08697005, ..., -0.08542009,\n",
      "        -0.03507728, -0.00512516]], dtype=float32)>, <tf.Variable 'bidirectional/forward_lstm/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[ 0.00255853, -0.07332507, -0.07608292, ...,  0.05250692,\n",
      "        -0.04840698, -0.00628533],\n",
      "       [-0.03541579, -0.00275227,  0.02615269, ...,  0.03240783,\n",
      "         0.00798426,  0.15142982],\n",
      "       [-0.04007885,  0.00324979, -0.05056669, ..., -0.0073323 ,\n",
      "        -0.11204518, -0.00263488],\n",
      "       ...,\n",
      "       [-0.0577609 ,  0.0666657 ,  0.07584789, ...,  0.07809884,\n",
      "         0.11928307,  0.13002808],\n",
      "       [-0.01778106, -0.02909178,  0.08556729, ...,  0.11472583,\n",
      "         0.01881923,  0.05705209],\n",
      "       [-0.0501372 , -0.01708891,  0.09245217, ...,  0.10642427,\n",
      "         0.08521272, -0.0235111 ]], dtype=float32)>, <tf.Variable 'bidirectional/forward_lstm/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([ 4.46019648e-03, -1.27258644e-01, -1.48304343e-01, -1.31655559e-01,\n",
      "       -1.25025228e-01, -5.66928312e-02, -5.72303832e-02, -1.92523837e-01,\n",
      "       -6.62173256e-02, -9.86469388e-02, -4.32165861e-02, -9.86632928e-02,\n",
      "       -4.26426120e-02, -5.15689366e-02, -5.87997511e-02, -4.10413742e-02,\n",
      "       -4.20928039e-02, -4.80227284e-02, -1.39653489e-01, -6.25841916e-02,\n",
      "       -1.05669640e-01, -2.82995403e-02, -7.36393854e-02, -8.80220234e-02,\n",
      "       -1.03266001e-01, -1.09870382e-01, -1.01973638e-01, -3.31930593e-02,\n",
      "       -1.36526123e-01, -8.63470733e-02, -6.47664517e-02, -1.06755093e-01,\n",
      "       -1.05392925e-01, -1.13569781e-01, -8.32143649e-02, -8.13265219e-02,\n",
      "       -8.53459090e-02, -7.28659108e-02, -9.71070006e-02, -6.43120185e-02,\n",
      "       -7.80595839e-02, -9.57932770e-02, -8.31432715e-02, -1.65047556e-01,\n",
      "       -5.91522269e-02, -7.63405859e-02, -8.31836611e-02, -9.44069847e-02,\n",
      "       -6.34198040e-02, -8.23282823e-02, -2.01615156e-03, -7.39087388e-02,\n",
      "       -8.26723650e-02, -1.36266142e-01, -1.03065722e-01, -7.69906770e-03,\n",
      "       -4.60052453e-02, -4.56918217e-02, -6.63664564e-02, -9.25936326e-02,\n",
      "       -1.42078638e-01, -9.61287841e-02, -7.15969130e-02, -3.67995724e-02,\n",
      "       -1.20760523e-01, -6.41657338e-02, -6.58979788e-02, -9.70623195e-02,\n",
      "       -1.01063237e-01, -6.69853017e-02, -3.26973610e-02, -1.31834641e-01,\n",
      "       -9.71116796e-02, -5.76002970e-02, -4.85108644e-02, -5.97543716e-02,\n",
      "       -4.03917432e-02, -8.22700709e-02, -6.77055866e-02, -1.34295553e-01,\n",
      "       -3.33689339e-02, -6.59791157e-02, -1.02808669e-01, -8.00663531e-02,\n",
      "       -5.29640615e-02, -3.32865119e-02, -7.51202554e-02, -9.34042335e-02,\n",
      "       -4.77484949e-02, -9.78247747e-02, -5.51484041e-02, -3.86829674e-02,\n",
      "       -3.87392864e-02, -5.68882413e-02, -6.40813336e-02, -6.90048113e-02,\n",
      "       -2.51718182e-02, -3.44284810e-02, -6.84449300e-02, -6.71142898e-03,\n",
      "       -1.21334419e-01, -1.21941686e-01, -4.87063602e-02, -1.32558450e-01,\n",
      "       -1.03835635e-01, -6.20153248e-02, -1.00431666e-01, -4.62092310e-02,\n",
      "       -3.40623111e-02, -1.26276061e-01, -1.20940879e-01, -1.38722494e-01,\n",
      "       -1.19939178e-01, -8.01371485e-02, -1.00498922e-01, -9.77374092e-02,\n",
      "       -7.27721229e-02, -4.96717952e-02, -1.21795319e-01, -6.66866452e-02,\n",
      "       -6.69880211e-02, -8.66863355e-02, -8.68279412e-02, -3.72558944e-02,\n",
      "       -1.90589391e-02, -5.79503141e-02, -7.71427751e-02, -8.95400718e-02,\n",
      "        1.02430320e+00,  9.17403877e-01,  8.97389948e-01,  8.93809378e-01,\n",
      "        8.82661104e-01,  9.39104438e-01,  9.27861154e-01,  8.63288045e-01,\n",
      "        9.03199852e-01,  9.03608143e-01,  9.37064707e-01,  9.23382044e-01,\n",
      "        9.36786830e-01,  9.56044078e-01,  9.59016085e-01,  9.55577672e-01,\n",
      "        9.12585616e-01,  9.60311294e-01,  9.06919360e-01,  9.55765069e-01,\n",
      "        8.76312792e-01,  9.41093445e-01,  9.11165476e-01,  9.57684696e-01,\n",
      "        9.20831323e-01,  9.00113344e-01,  9.07322645e-01,  1.01444292e+00,\n",
      "        8.98168802e-01,  8.69594574e-01,  9.18677688e-01,  9.17941570e-01,\n",
      "        9.23016012e-01,  8.87861431e-01,  9.18675601e-01,  9.23958898e-01,\n",
      "        9.41241920e-01,  9.05201316e-01,  9.38722551e-01,  9.42921937e-01,\n",
      "        9.40704226e-01,  9.61829185e-01,  9.03485298e-01,  9.26894069e-01,\n",
      "        9.78252232e-01,  9.19172704e-01,  9.74089026e-01,  9.24062729e-01,\n",
      "        9.34779942e-01,  9.40487802e-01,  9.92347479e-01,  9.40526187e-01,\n",
      "        9.29381311e-01,  8.56064379e-01,  8.96993756e-01,  9.56381917e-01,\n",
      "        9.66783524e-01,  9.44717050e-01,  9.39299464e-01,  9.54153359e-01,\n",
      "        8.79380107e-01,  9.35317457e-01,  9.50744152e-01,  9.87860620e-01,\n",
      "        9.42858398e-01,  9.72665012e-01,  9.24362659e-01,  9.05110061e-01,\n",
      "        9.19951916e-01,  9.19045150e-01,  9.57049012e-01,  8.52770507e-01,\n",
      "        8.91431749e-01,  8.71300936e-01,  9.63529170e-01,  9.23626304e-01,\n",
      "        9.64043140e-01,  8.69148016e-01,  9.54419434e-01,  9.26278770e-01,\n",
      "        9.51488554e-01,  9.10748422e-01,  9.09860909e-01,  9.20663774e-01,\n",
      "        9.26695168e-01,  9.60551023e-01,  9.25345182e-01,  8.99094343e-01,\n",
      "        9.49440598e-01,  9.55494523e-01,  9.49086428e-01,  9.69099820e-01,\n",
      "        9.09473062e-01,  9.15929735e-01,  9.60876703e-01,  9.03404474e-01,\n",
      "        9.62399602e-01,  9.33672667e-01,  9.54785109e-01,  1.02465165e+00,\n",
      "        8.94461989e-01,  8.97566199e-01,  9.25183415e-01,  8.92759264e-01,\n",
      "        9.41856325e-01,  9.21231806e-01,  8.51815999e-01,  9.91993427e-01,\n",
      "        9.49930727e-01,  8.98572266e-01,  8.83655488e-01,  8.79873335e-01,\n",
      "        8.88182700e-01,  9.47747052e-01,  9.33182001e-01,  9.20995414e-01,\n",
      "        9.22333717e-01,  9.72538650e-01,  8.71733546e-01,  9.05249834e-01,\n",
      "        9.17030156e-01,  8.81301641e-01,  9.70757484e-01,  9.49277520e-01,\n",
      "        9.72853541e-01,  9.51271415e-01,  9.30462599e-01,  8.97465944e-01,\n",
      "       -4.53682523e-03,  2.36922484e-02,  2.53973622e-02, -4.66893464e-02,\n",
      "       -2.15813518e-02, -3.51233557e-02, -2.46614125e-03, -2.28018872e-02,\n",
      "       -1.07784299e-02, -3.83485341e-03, -2.25812308e-02, -9.71740391e-03,\n",
      "        4.16057929e-03, -2.08915826e-02,  1.89433787e-02, -2.55458113e-02,\n",
      "       -1.52288200e-02, -2.60417759e-02, -3.41165029e-02, -5.18143885e-02,\n",
      "       -6.17791153e-03,  2.56180800e-02, -2.98129842e-02, -3.51439007e-02,\n",
      "       -3.11494507e-02, -5.77795170e-02, -5.49413674e-02, -6.69518858e-02,\n",
      "       -2.48002335e-02,  1.35618979e-02, -3.34328413e-02, -1.06089571e-02,\n",
      "       -2.90268976e-02, -5.29197119e-02,  8.37553386e-03, -4.74691428e-02,\n",
      "       -3.27992067e-02, -5.55046648e-02, -2.21903715e-02, -2.33972371e-02,\n",
      "       -3.70708294e-02, -4.60302569e-02, -3.56825851e-02, -6.73751161e-02,\n",
      "       -4.48044017e-02, -2.55036876e-02, -6.35241792e-02, -5.09056114e-02,\n",
      "       -4.05353233e-02, -2.68749483e-02, -2.51244903e-02, -1.75707899e-02,\n",
      "       -2.61393040e-02, -2.63573043e-02, -7.27965450e-03, -4.90055941e-02,\n",
      "       -3.20945904e-02, -2.61810664e-02, -5.68928104e-03, -1.78013593e-02,\n",
      "       -2.53194645e-02, -4.39408720e-02, -4.03625891e-02, -6.04264028e-02,\n",
      "       -5.98625094e-02, -5.03970608e-02,  1.18614174e-02, -1.24880886e-02,\n",
      "       -5.90186380e-02, -9.29733273e-03,  2.64140703e-02, -4.60341051e-02,\n",
      "       -1.43259494e-02, -2.36295406e-02,  9.56226373e-04, -2.98062600e-02,\n",
      "       -3.00625693e-02,  2.50033215e-02, -5.42933419e-02, -6.08369559e-02,\n",
      "        2.74966620e-02, -9.47236735e-03, -4.60557677e-02, -1.02516441e-02,\n",
      "       -5.89780621e-02,  2.55268738e-02, -2.09083930e-02, -7.80841848e-03,\n",
      "        4.19770135e-03, -2.21498478e-02, -5.54067940e-02,  3.86828650e-03,\n",
      "        8.50023516e-03,  2.06596665e-02, -1.05601111e-02, -7.65056536e-03,\n",
      "       -5.76686859e-03, -3.84976459e-03, -3.04634161e-02, -4.19188384e-03,\n",
      "       -2.92369425e-02, -1.82200503e-02, -7.69822299e-03, -3.54618467e-02,\n",
      "       -2.37222370e-02, -1.54565861e-02, -4.72209640e-02, -7.70596266e-02,\n",
      "       -2.20334157e-02, -1.84684508e-02, -4.25571576e-02, -4.04221900e-02,\n",
      "       -2.06579510e-02, -7.72253424e-02, -4.29761074e-02, -1.23071717e-02,\n",
      "       -7.34975561e-03, -2.38666069e-02, -1.69987082e-02, -4.03309334e-03,\n",
      "       -3.93618159e-02, -2.34809108e-02, -4.91532534e-02, -1.29287159e-02,\n",
      "        1.63847953e-02, -5.30700088e-02, -4.83008660e-02,  1.02520054e-02,\n",
      "       -2.49274401e-03, -1.14859104e-01, -1.31739587e-01, -1.25459194e-01,\n",
      "       -1.20055214e-01, -7.40066618e-02, -5.86093999e-02, -1.65420935e-01,\n",
      "       -6.85482323e-02, -9.51994210e-02, -4.35274504e-02, -7.83003047e-02,\n",
      "       -4.84022312e-02, -3.93104255e-02, -5.61428815e-02, -4.34915014e-02,\n",
      "       -4.63239327e-02, -4.63285036e-02, -1.27629116e-01, -4.36471961e-02,\n",
      "       -1.12906061e-01, -2.37628818e-02, -7.17472360e-02, -7.91743174e-02,\n",
      "       -9.06515121e-02, -1.10261865e-01, -8.91814604e-02, -3.26389186e-02,\n",
      "       -1.22133255e-01, -8.71333852e-02, -7.26509318e-02, -9.22240615e-02,\n",
      "       -9.94954929e-02, -1.14322484e-01, -7.55806789e-02, -8.53023976e-02,\n",
      "       -8.32437202e-02, -5.71316108e-02, -7.75713101e-02, -6.13339990e-02,\n",
      "       -7.33496770e-02, -7.63384998e-02, -8.59249234e-02, -1.57437891e-01,\n",
      "       -5.37230708e-02, -8.11597183e-02, -8.99467841e-02, -8.90684277e-02,\n",
      "       -6.69665188e-02, -8.10576603e-02, -2.83484324e-03, -7.77724683e-02,\n",
      "       -7.83984959e-02, -1.21030904e-01, -1.02234200e-01, -1.73532162e-02,\n",
      "       -3.85827981e-02, -5.09461872e-02, -6.60147518e-02, -9.40007046e-02,\n",
      "       -1.22552782e-01, -9.50392634e-02, -7.11042136e-02, -4.53041494e-02,\n",
      "       -1.26003131e-01, -6.73056096e-02, -6.96427450e-02, -1.02143444e-01,\n",
      "       -6.65767714e-02, -5.88623248e-02, -3.51585411e-02, -1.03635356e-01,\n",
      "       -9.10685882e-02, -6.25121295e-02, -5.19276485e-02, -7.43342862e-02,\n",
      "       -4.37053964e-02, -8.38321373e-02, -6.85568526e-02, -1.05189644e-01,\n",
      "       -3.54038775e-02, -7.14623854e-02, -9.55415294e-02, -7.31829032e-02,\n",
      "       -5.65055311e-02, -4.34547886e-02, -8.54957029e-02, -8.82494673e-02,\n",
      "       -4.94285636e-02, -9.36713070e-02, -5.14863096e-02, -2.45960075e-02,\n",
      "       -3.18058543e-02, -5.38698360e-02, -6.99995607e-02, -6.91569224e-02,\n",
      "       -2.22127344e-02, -3.42964269e-02, -6.96208626e-02,  3.23002879e-03,\n",
      "       -1.21478558e-01, -1.19716778e-01, -4.93213087e-02, -1.28130987e-01,\n",
      "       -1.02544591e-01, -5.24577126e-02, -9.93988663e-02, -4.17556055e-02,\n",
      "       -3.58193330e-02, -1.31913304e-01, -1.23906538e-01, -1.34173453e-01,\n",
      "       -1.02087043e-01, -7.10662752e-02, -8.87547508e-02, -9.01739150e-02,\n",
      "       -7.24889114e-02, -4.85617816e-02, -1.23832889e-01, -6.13978393e-02,\n",
      "       -4.54200990e-02, -8.18502977e-02, -9.25525427e-02, -3.21836993e-02,\n",
      "       -3.08459904e-02, -4.19004336e-02, -7.57409185e-02, -7.01259449e-02],\n",
      "      dtype=float32)>, <tf.Variable 'bidirectional/backward_lstm/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[-0.0811804 , -0.02522787, -0.07144891, ..., -0.01096731,\n",
      "        -0.00631499,  0.03052405],\n",
      "       [-0.02619976,  0.12407248, -0.01009613, ...,  0.01255249,\n",
      "         0.04134414,  0.03231375],\n",
      "       [ 0.01739484,  0.03219488,  0.08977433, ...,  0.0997467 ,\n",
      "        -0.00816666,  0.06846675],\n",
      "       ...,\n",
      "       [ 0.10289053,  0.02584573, -0.00329831, ...,  0.09691862,\n",
      "         0.04626718, -0.03610575],\n",
      "       [-0.02555924, -0.00941771,  0.03769516, ..., -0.0801517 ,\n",
      "         0.04383031,  0.04035218],\n",
      "       [-0.01369374,  0.10026901, -0.07391471, ..., -0.03631742,\n",
      "         0.13023463, -0.00527536]], dtype=float32)>, <tf.Variable 'bidirectional/backward_lstm/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[ 8.56990814e-02, -8.83749966e-03,  3.24042141e-02, ...,\n",
      "        -1.79088674e-02, -5.38422018e-02, -2.14991141e-02],\n",
      "       [-1.16197290e-02,  2.04987004e-02,  5.16268872e-02, ...,\n",
      "         1.54316425e-01, -6.33087307e-02,  2.61410046e-02],\n",
      "       [ 9.49265994e-03, -1.06273092e-01,  3.51731782e-03, ...,\n",
      "         1.32884486e-02, -1.20394140e-01, -4.62233014e-02],\n",
      "       ...,\n",
      "       [ 2.36052647e-02, -7.74721056e-02,  1.14904353e-02, ...,\n",
      "         7.60669708e-02, -2.24557444e-02,  1.05060682e-01],\n",
      "       [ 1.19834304e-01, -2.23261118e-02, -2.40224181e-05, ...,\n",
      "         3.58625758e-03,  1.88130373e-03,  1.75276548e-01],\n",
      "       [-6.96056662e-03, -6.78294674e-02, -4.21172008e-02, ...,\n",
      "        -2.69879904e-02,  7.85623565e-02, -1.81270894e-02]], dtype=float32)>, <tf.Variable 'bidirectional/backward_lstm/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([-4.56204340e-02, -9.41465572e-02, -2.26056408e-02, -3.43550257e-02,\n",
      "       -4.62648571e-02, -3.76394093e-02, -3.75785083e-02, -5.78969643e-02,\n",
      "       -5.23247048e-02, -4.49112840e-02, -6.99405596e-02, -3.74461301e-02,\n",
      "       -4.61665466e-02, -4.44482118e-02, -1.31790757e-01, -7.63504431e-02,\n",
      "       -6.82563633e-02,  1.88358710e-03, -4.12622355e-02, -1.28702465e-02,\n",
      "       -1.00241773e-01, -4.99167144e-02, -2.71249525e-02, -9.33403745e-02,\n",
      "       -6.89090565e-02, -8.90514031e-02, -5.45575470e-02, -5.37776910e-02,\n",
      "       -4.45269141e-03, -5.76690771e-02, -4.37997468e-02, -1.05849624e-01,\n",
      "        1.89995449e-02, -1.18946256e-02, -6.17982522e-02, -4.97120917e-02,\n",
      "       -8.08656663e-02, -7.15545416e-02, -3.41748111e-02, -8.37369822e-03,\n",
      "       -3.92800793e-02, -6.02469184e-02, -9.13833976e-02, -6.77795336e-02,\n",
      "       -4.35917564e-02, -8.21084976e-02, -1.51225822e-02, -4.74353507e-02,\n",
      "       -1.44277662e-02,  4.90037864e-03, -1.15568936e-01, -1.57714430e-02,\n",
      "       -1.57481208e-02,  4.22337428e-02, -9.00646076e-02, -3.43162492e-02,\n",
      "       -6.72921240e-02, -5.63992038e-02,  2.98724859e-03, -3.88007471e-03,\n",
      "       -3.53955738e-02, -4.09993380e-02, -1.61973108e-02, -9.94077697e-02,\n",
      "       -4.54855263e-02, -3.80928032e-02, -5.34637198e-02, -2.23064255e-02,\n",
      "       -2.77214106e-02, -4.87263203e-02, -3.55166346e-02, -6.08230680e-02,\n",
      "       -6.65965155e-02, -6.87285364e-02, -7.55361393e-02, -6.15650453e-02,\n",
      "       -7.47223347e-02, -5.72667122e-02, -2.21342519e-02, -6.21220879e-02,\n",
      "       -3.78269665e-02, -9.66152251e-02,  8.14204291e-03, -3.74780037e-02,\n",
      "       -4.51533571e-02, -1.71906389e-02, -7.32111707e-02, -5.28453179e-02,\n",
      "       -5.76880872e-02, -8.45714360e-02, -7.04254583e-02, -8.18075016e-02,\n",
      "       -5.22046760e-02, -5.17392755e-02, -4.09016423e-02, -1.45504214e-02,\n",
      "       -9.92300436e-02, -1.03585936e-01, -5.00041768e-02, -3.17819081e-02,\n",
      "       -7.19736293e-02, -9.30034816e-02, -7.12424144e-02, -3.52973379e-02,\n",
      "       -3.81258801e-02, -2.48773899e-02, -3.85346636e-02, -3.21866162e-02,\n",
      "       -8.60416815e-02, -4.71532270e-02, -3.04952692e-02, -2.72994637e-02,\n",
      "       -5.58353066e-02, -7.95924067e-02, -8.08008313e-02, -4.60268520e-02,\n",
      "       -3.86277959e-02, -3.55689041e-02, -6.69072196e-02, -8.36478919e-02,\n",
      "       -2.64691040e-02, -7.47332647e-02, -6.36022389e-02, -7.99800362e-03,\n",
      "       -9.31956545e-02, -5.52027710e-02, -4.54026125e-02, -7.79207842e-03,\n",
      "        9.36701775e-01,  9.49460149e-01,  9.92220819e-01,  9.30292606e-01,\n",
      "        9.89044487e-01,  9.76190269e-01,  9.73000169e-01,  9.22140658e-01,\n",
      "        9.61745322e-01,  9.69286561e-01,  9.44315314e-01,  9.46275055e-01,\n",
      "        9.80982184e-01,  9.85083640e-01,  9.00084257e-01,  9.29411709e-01,\n",
      "        9.58079517e-01,  9.90146041e-01,  9.68273997e-01,  1.02889621e+00,\n",
      "        8.84003103e-01,  9.71934736e-01,  1.01658261e+00,  9.11946774e-01,\n",
      "        9.18991745e-01,  9.29456055e-01,  9.29953337e-01,  9.48134184e-01,\n",
      "        1.00118363e+00,  9.39762771e-01,  1.02398789e+00,  9.08289611e-01,\n",
      "        1.01015162e+00,  9.60243285e-01,  9.29154694e-01,  9.44719374e-01,\n",
      "        9.40819860e-01,  9.33769882e-01,  9.60405171e-01,  9.67407048e-01,\n",
      "        9.64342535e-01,  9.39249218e-01,  8.75255346e-01,  9.40174699e-01,\n",
      "        9.37048495e-01,  9.07307386e-01,  9.98992682e-01,  9.54453290e-01,\n",
      "        9.75198865e-01,  9.79809940e-01,  9.09709096e-01,  9.31246459e-01,\n",
      "        9.88002658e-01,  1.04869390e+00,  9.25178230e-01,  1.00437081e+00,\n",
      "        9.48923409e-01,  9.58593130e-01,  9.51033533e-01,  9.90878165e-01,\n",
      "        9.57764030e-01,  9.83107984e-01,  1.01014709e+00,  9.12538767e-01,\n",
      "        9.48147237e-01,  9.47373569e-01,  9.37294841e-01,  9.82619524e-01,\n",
      "        1.01463556e+00,  9.58548903e-01,  9.87848997e-01,  9.51986253e-01,\n",
      "        9.46325898e-01,  9.22721207e-01,  9.37287688e-01,  9.57817614e-01,\n",
      "        8.28416288e-01,  9.24400389e-01,  9.45272207e-01,  9.43001390e-01,\n",
      "        9.43001926e-01,  9.15350437e-01,  1.03568137e+00,  9.61008966e-01,\n",
      "        9.44397032e-01,  9.71499920e-01,  9.38328207e-01,  9.36382413e-01,\n",
      "        9.82839048e-01,  8.83395374e-01,  9.69040394e-01,  9.05114830e-01,\n",
      "        9.29346383e-01,  9.40317690e-01,  9.74894226e-01,  1.02049685e+00,\n",
      "        9.05624926e-01,  9.27317321e-01,  9.44631517e-01,  1.01385033e+00,\n",
      "        9.56743181e-01,  9.04190123e-01,  9.03160870e-01,  9.54104781e-01,\n",
      "        9.92772996e-01,  9.33074772e-01,  9.58246589e-01,  1.02598965e+00,\n",
      "        9.49762881e-01,  9.25958514e-01,  1.00091386e+00,  9.96609032e-01,\n",
      "        9.44102705e-01,  9.55258369e-01,  8.85326087e-01,  9.43966448e-01,\n",
      "        9.84169006e-01,  9.69785988e-01,  9.61785316e-01,  9.29746270e-01,\n",
      "        9.64420140e-01,  9.41000760e-01,  9.43172574e-01,  9.80705619e-01,\n",
      "        9.37917709e-01,  9.53784406e-01,  9.86624479e-01,  9.98427033e-01,\n",
      "        2.26267651e-02, -1.61434524e-02,  1.43158687e-02, -1.53852087e-02,\n",
      "       -3.55018713e-02, -1.61797386e-02, -1.61530962e-03, -2.65543982e-02,\n",
      "       -4.12069820e-02, -2.43119728e-02, -2.07595266e-02, -1.03797847e-02,\n",
      "       -6.78077247e-03, -3.16587165e-02, -5.38819171e-02, -3.42719778e-02,\n",
      "       -1.66470632e-02, -8.27849656e-03, -1.03065204e-02, -5.90249933e-02,\n",
      "       -1.76653806e-02, -1.13843577e-02, -5.20639606e-02, -3.28558944e-02,\n",
      "       -3.08916029e-02, -1.62664987e-02,  3.60127762e-02, -1.20872734e-02,\n",
      "       -3.60934809e-02, -1.45648206e-02, -4.12724391e-02, -1.39890620e-02,\n",
      "        2.34919768e-02, -3.32738571e-02, -1.63997780e-03, -5.66671044e-03,\n",
      "       -3.29099409e-02, -4.98501630e-03, -2.67663002e-02, -2.56899521e-02,\n",
      "       -4.38102940e-03, -3.88394445e-02, -1.22737363e-02, -4.51018959e-02,\n",
      "       -2.07647290e-02, -3.39747518e-02, -6.20264281e-03, -1.53653016e-02,\n",
      "       -1.78877525e-02,  4.52578329e-02, -3.86851318e-02,  1.47335464e-02,\n",
      "       -3.43709104e-02, -1.52843129e-02,  7.76925997e-04, -4.13777167e-03,\n",
      "       -2.99464501e-02, -3.95714678e-02, -4.87157027e-04,  2.93186828e-02,\n",
      "        6.12916937e-03, -2.04667430e-02,  7.67757930e-03, -7.72132678e-03,\n",
      "        1.69565398e-02, -1.22553688e-02, -5.04374690e-03, -2.77883671e-02,\n",
      "       -2.51623187e-02,  1.72575116e-02, -4.67429943e-02, -2.24784929e-02,\n",
      "       -1.98549945e-02, -1.06323510e-03, -8.94062920e-04, -2.95271836e-02,\n",
      "       -1.83096714e-02,  1.47939492e-02, -3.41871195e-02,  8.51833448e-03,\n",
      "       -2.50947140e-02, -1.46837691e-02, -3.99744026e-02,  5.90783963e-03,\n",
      "       -1.68206934e-02,  1.34478444e-02, -1.92604922e-02, -9.00318660e-03,\n",
      "       -2.86855437e-02, -4.21694200e-03, -4.94559444e-02, -4.20926139e-02,\n",
      "       -3.72128598e-02, -2.47736797e-02, -3.59051377e-02, -4.67742421e-02,\n",
      "        1.15372073e-02, -3.49387862e-02, -2.46112552e-02, -2.65911706e-02,\n",
      "       -6.31220341e-02,  5.45296306e-03, -6.01032143e-03, -2.43253969e-02,\n",
      "       -5.64703196e-02,  1.26592312e-02, -1.42735299e-02, -5.56977913e-02,\n",
      "       -3.93853299e-02, -9.80689283e-03, -3.03663779e-04, -5.49667589e-02,\n",
      "       -2.17871722e-02, -3.02488916e-02, -2.68940674e-03, -1.10191870e-02,\n",
      "       -2.40880158e-02, -3.17409188e-02, -2.74423044e-02, -3.04604545e-02,\n",
      "        1.81226172e-02, -2.83603109e-02, -1.90536175e-02, -2.52321586e-02,\n",
      "       -8.27339012e-03, -2.36461274e-02, -2.41624918e-02,  3.73437330e-02,\n",
      "       -5.35621904e-02, -9.56192985e-02, -2.59100739e-02, -3.40386443e-02,\n",
      "       -4.50852737e-02, -5.75658903e-02, -4.26803418e-02, -6.52355477e-02,\n",
      "       -5.72916567e-02, -4.47841473e-02, -7.48396590e-02, -4.53417189e-02,\n",
      "       -3.52889821e-02, -4.82944176e-02, -1.62632540e-01, -8.32211375e-02,\n",
      "       -6.96518123e-02,  9.88265732e-04, -5.31477332e-02, -1.83887333e-02,\n",
      "       -1.16692528e-01, -5.52559607e-02, -2.89524533e-02, -8.67525712e-02,\n",
      "       -8.02833065e-02, -1.11411855e-01, -8.15791637e-02, -5.64611480e-02,\n",
      "       -1.14931930e-02, -7.24557191e-02, -5.74724227e-02, -1.07317641e-01,\n",
      "       -1.48325535e-02, -4.31790538e-02, -6.15360551e-02, -4.89837378e-02,\n",
      "       -7.87959099e-02, -8.04901347e-02, -4.07100581e-02, -1.59428604e-02,\n",
      "       -4.63725664e-02, -7.18266517e-02, -1.03378907e-01, -6.51955307e-02,\n",
      "       -5.30542284e-02, -8.77918005e-02, -1.31369252e-02, -7.28365257e-02,\n",
      "       -3.52572128e-02, -5.42138293e-02, -1.18169457e-01, -2.24683229e-02,\n",
      "       -6.58704899e-03,  2.37005837e-02, -8.85767415e-02, -7.55663589e-02,\n",
      "       -7.74728730e-02, -7.12166131e-02, -2.80990195e-03, -1.87885389e-02,\n",
      "       -3.58572304e-02, -5.42615205e-02, -5.64260073e-02, -1.08706765e-01,\n",
      "       -4.75849845e-02, -3.24073471e-02, -5.30082993e-02, -4.97232080e-02,\n",
      "       -3.70790288e-02, -5.37975803e-02, -4.18170728e-02, -7.94227570e-02,\n",
      "       -7.10106269e-02, -9.04711187e-02, -6.59597814e-02, -6.40907362e-02,\n",
      "       -7.00293407e-02, -6.04524724e-02, -1.61710978e-02, -7.18880892e-02,\n",
      "       -5.31482510e-02, -1.01705253e-01,  8.06149747e-03, -6.33068979e-02,\n",
      "       -5.55807538e-02, -4.76580188e-02, -7.69870728e-02, -5.68324290e-02,\n",
      "       -6.37979656e-02, -8.50249380e-02, -7.29115084e-02, -8.43996629e-02,\n",
      "       -6.96460456e-02, -6.26225695e-02, -5.82310148e-02, -3.94052416e-02,\n",
      "       -9.81350914e-02, -1.04244627e-01, -6.34345636e-02, -5.48127815e-02,\n",
      "       -7.27604851e-02, -1.01205215e-01, -7.48841166e-02, -4.13011834e-02,\n",
      "       -3.79088596e-02, -3.11658550e-02, -3.37701216e-02, -2.53193378e-02,\n",
      "       -9.71588641e-02, -4.96920235e-02, -9.55274478e-02, -5.45882918e-02,\n",
      "       -5.45728803e-02, -7.63899013e-02, -8.68691728e-02, -5.39754368e-02,\n",
      "       -4.92388345e-02, -3.66614200e-02, -7.26910681e-02, -9.61913690e-02,\n",
      "       -2.75886897e-02, -8.04556161e-02, -7.14556128e-02, -1.10735623e-02,\n",
      "       -8.75725001e-02, -6.15078695e-02, -3.32982987e-02, -4.21925001e-02],\n",
      "      dtype=float32)>, <tf.Variable 'dense/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
      "array([[-0.17135337, -0.0901871 , -0.14501868, ..., -0.08312475,\n",
      "        -0.06131322,  0.11243248],\n",
      "       [ 0.03840246, -0.09979244,  0.08667523, ..., -0.05584343,\n",
      "        -0.00310386, -0.0872181 ],\n",
      "       [-0.02316101,  0.06042412, -0.07302384, ..., -0.10842652,\n",
      "        -0.05500403, -0.05686613],\n",
      "       ...,\n",
      "       [ 0.00316671, -0.04226459,  0.00644751, ...,  0.02232357,\n",
      "        -0.00123584,  0.0399445 ],\n",
      "       [ 0.10874307, -0.08258834,  0.07217932, ...,  0.09515546,\n",
      "        -0.0904415 , -0.10631403],\n",
      "       [-0.00637844,  0.05626678,  0.09189395, ..., -0.05449324,\n",
      "        -0.08369394, -0.07684563]], dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([-0.0118743 , -0.04281247, -0.00967225, -0.01900138, -0.03161383,\n",
      "       -0.02281332, -0.02920396,  0.00759835, -0.02406637, -0.05597725,\n",
      "       -0.01266294, -0.02571553, -0.01931464, -0.00602195, -0.05316788,\n",
      "        0.03293328, -0.00240386, -0.01627076, -0.01296323, -0.03362317,\n",
      "        0.01140624, -0.04719517, -0.03062228, -0.0304444 , -0.02510977,\n",
      "       -0.02458379, -0.01876775,  0.00401992, -0.00727418, -0.03198833,\n",
      "       -0.01787904, -0.03502673, -0.03316606, -0.01904777,  0.01778222,\n",
      "       -0.03150023, -0.04061816,  0.03082678,  0.00536105, -0.03060428,\n",
      "       -0.02749395,  0.00211542,  0.02238294, -0.02463426, -0.03713684,\n",
      "       -0.02401759, -0.0523901 ,  0.01905294, -0.03673548, -0.0169268 ,\n",
      "       -0.04207291, -0.01903268, -0.02055408, -0.04288517, -0.00717667,\n",
      "        0.02177652, -0.01895715, -0.01948458, -0.01205685,  0.00281287,\n",
      "        0.02562842, -0.03493511,  0.00178164, -0.0041789 , -0.02622135,\n",
      "       -0.02868205, -0.02481061, -0.04184524, -0.020973  , -0.02022763,\n",
      "       -0.01708058, -0.02022484, -0.01692114, -0.02555911, -0.02164987,\n",
      "        0.03895072, -0.02065393, -0.01481271,  0.01081601, -0.04867439,\n",
      "       -0.01250822, -0.00729182, -0.02205781,  0.01880219,  0.00720032,\n",
      "        0.00166875, -0.03053487,  0.02859776, -0.02401329, -0.02829798,\n",
      "       -0.01925465, -0.0293272 , -0.04624689, -0.01492852, -0.00233806,\n",
      "       -0.04371347,  0.00918104, -0.04023967, -0.02848398, -0.06381418,\n",
      "       -0.07746681, -0.03175826, -0.05694761, -0.01139213, -0.01615041,\n",
      "       -0.00270473, -0.04695244, -0.01943516, -0.02523717,  0.05083976,\n",
      "       -0.0154752 , -0.01271635, -0.04122049,  0.02266811, -0.01185228,\n",
      "        0.00274084, -0.02337935, -0.01905081,  0.02402452, -0.00283296,\n",
      "        0.0164432 , -0.01527551, -0.06844645, -0.03624196, -0.02442082,\n",
      "       -0.01808709, -0.03763722, -0.02490986], dtype=float32)>, <tf.Variable 'dense_1/kernel:0' shape=(128, 32) dtype=float32, numpy=\n",
      "array([[ 0.18088357, -0.15852512,  0.04682717, ..., -0.14164339,\n",
      "        -0.04259805,  0.03833415],\n",
      "       [-0.02008772, -0.02959931,  0.15233186, ...,  0.12069778,\n",
      "        -0.16778913, -0.0620711 ],\n",
      "       [ 0.18896677,  0.09746379,  0.02204145, ...,  0.07048742,\n",
      "         0.11574575,  0.05561269],\n",
      "       ...,\n",
      "       [ 0.18852088, -0.18603721,  0.07560437, ...,  0.05353304,\n",
      "        -0.15377238,  0.04169366],\n",
      "       [-0.01202789,  0.04520997,  0.1212763 , ...,  0.17832264,\n",
      "        -0.15347232, -0.02642562],\n",
      "       [-0.17580193, -0.17483786, -0.03636207, ...,  0.04273316,\n",
      "        -0.09442938,  0.21815236]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-0.02074888, -0.00891908, -0.0231903 , -0.01858154, -0.02548109,\n",
      "       -0.01510128,  0.05403754, -0.02363066, -0.04687547, -0.02034999,\n",
      "       -0.02607559, -0.0177637 ,  0.00119449, -0.03094605, -0.03595412,\n",
      "       -0.0884842 , -0.02136988,  0.01897386, -0.03402149,  0.06186648,\n",
      "        0.00878521, -0.04934624, -0.03890239,  0.01332096, -0.00172751,\n",
      "       -0.00697764,  0.00847349, -0.02061123, -0.01890825, -0.03545219,\n",
      "       -0.01866665, -0.03390652], dtype=float32)>, <tf.Variable 'dense_2/kernel:0' shape=(32, 8) dtype=float32, numpy=\n",
      "array([[-4.12213564e-01,  1.69071317e-01,  4.62873280e-02,\n",
      "         1.86419204e-01, -3.58995646e-02,  2.60777086e-01,\n",
      "        -3.60693485e-01,  7.90662766e-02],\n",
      "       [-9.71357152e-02, -2.57026166e-01,  3.71438414e-02,\n",
      "        -3.60007405e-01,  3.04012448e-01,  3.10588360e-01,\n",
      "        -3.25501144e-01, -2.41529554e-01],\n",
      "       [-2.94354796e-01, -1.00302234e-01, -1.77368283e-01,\n",
      "        -1.97053943e-02,  3.08727264e-01,  2.14911136e-03,\n",
      "        -7.04375207e-02, -2.79141754e-01],\n",
      "       [-1.03455499e-01,  8.70394483e-02,  1.19137459e-01,\n",
      "        -3.42793763e-02, -8.25299919e-02,  3.47500294e-01,\n",
      "         2.23002061e-01, -2.65888125e-01],\n",
      "       [ 2.71550149e-01,  2.55719692e-01, -4.62300889e-02,\n",
      "         1.58776149e-01,  1.38912380e-01,  1.81824341e-01,\n",
      "        -3.00908715e-01,  5.43029569e-02],\n",
      "       [ 1.08579751e-02,  3.37888807e-01, -3.06876726e-04,\n",
      "         2.89222896e-01, -1.81837082e-01,  1.98378026e-01,\n",
      "        -8.47123861e-02,  1.49721235e-01],\n",
      "       [ 1.90294251e-01, -4.11481887e-01,  1.01927124e-01,\n",
      "         2.34804451e-01, -5.07120378e-02,  1.20318942e-01,\n",
      "        -7.79938176e-02,  3.12508829e-02],\n",
      "       [ 1.28032312e-01, -1.29998684e-01,  4.44065064e-01,\n",
      "        -1.60657331e-01, -4.39116061e-01,  5.07991076e-01,\n",
      "        -2.53109097e-01, -2.37261280e-01],\n",
      "       [-2.73917496e-01, -3.65384877e-01,  8.00329372e-02,\n",
      "         2.04062089e-02,  1.16560660e-01, -1.81714334e-02,\n",
      "        -1.97250366e-01, -2.08336264e-02],\n",
      "       [-1.18101925e-01, -7.44073838e-02,  2.76116490e-01,\n",
      "         9.72417817e-02,  1.57749981e-01, -6.57381415e-02,\n",
      "         1.10207707e-01, -6.58687279e-02],\n",
      "       [-2.17401400e-01, -5.07327467e-02,  2.33371943e-01,\n",
      "         3.53338450e-01,  7.07565472e-02,  2.39923239e-01,\n",
      "         3.54435295e-01, -1.87073961e-01],\n",
      "       [ 8.88760537e-02,  1.39786839e-01, -8.26521143e-02,\n",
      "         1.08650386e-01, -2.51798451e-01, -3.59297507e-02,\n",
      "         1.46570683e-01,  3.26598883e-01],\n",
      "       [-1.82495177e-01,  5.54485582e-02,  2.21952841e-01,\n",
      "        -2.66001463e-01,  4.30984087e-02,  1.99168742e-01,\n",
      "        -1.13316260e-01, -1.67323902e-01],\n",
      "       [-2.38047317e-01, -1.99538499e-01,  2.14704126e-01,\n",
      "        -3.45849395e-01,  3.21501255e-01, -9.15839076e-02,\n",
      "        -1.70874044e-01,  2.29161069e-01],\n",
      "       [-3.35857689e-01, -1.12132654e-02,  3.92913520e-01,\n",
      "        -2.26412311e-01, -2.94515610e-01,  1.85127959e-01,\n",
      "        -3.22198957e-01, -3.59102666e-01],\n",
      "       [-1.63586721e-01,  1.78144947e-01,  5.53523481e-01,\n",
      "         1.21487334e-01, -6.16222657e-02,  5.38727999e-01,\n",
      "         7.18514919e-02,  4.55263117e-03],\n",
      "       [-2.10896388e-01, -2.44896665e-01, -2.69671828e-01,\n",
      "        -1.75790593e-01,  2.16267675e-01, -2.03563403e-02,\n",
      "        -9.45688337e-02, -3.64943087e-01],\n",
      "       [-2.95690268e-01,  1.21449545e-01,  4.23269439e-03,\n",
      "        -2.80037969e-01,  1.24368005e-01,  2.76076198e-01,\n",
      "         1.62143812e-01, -3.92928660e-01],\n",
      "       [-2.51603395e-01, -1.23692654e-01, -2.68786728e-01,\n",
      "         2.19508305e-01,  2.80073404e-01, -2.74444044e-01,\n",
      "         1.78777173e-01,  2.17930973e-01],\n",
      "       [ 5.46568692e-01, -6.51447177e-02, -5.02657652e-01,\n",
      "        -5.04627125e-03,  4.53165099e-02, -1.33206263e-01,\n",
      "        -6.88019469e-02, -8.66766050e-02],\n",
      "       [ 7.31490646e-03, -1.16890468e-01,  9.78031158e-02,\n",
      "         1.99086264e-01,  6.90859975e-04, -1.95858911e-01,\n",
      "         2.30197564e-01,  1.83551103e-01],\n",
      "       [ 5.93215190e-02, -1.59481391e-01,  2.10589722e-01,\n",
      "         3.51732522e-02,  1.10909186e-01,  3.57753158e-01,\n",
      "         3.41634959e-01,  2.23868787e-01],\n",
      "       [ 1.53756235e-02,  1.86346397e-01,  4.76937229e-03,\n",
      "         1.81560129e-01,  2.46561944e-01,  3.62856090e-01,\n",
      "        -1.35787532e-01, -6.70466274e-02],\n",
      "       [-1.39739305e-01, -2.05386221e-01,  2.30913639e-01,\n",
      "        -1.90957516e-01, -1.94770381e-01, -6.27480745e-02,\n",
      "         2.62921572e-01,  2.07931563e-01],\n",
      "       [ 4.27918941e-01, -2.89802641e-01,  1.77857146e-01,\n",
      "         3.81303310e-01,  6.37744591e-02, -2.94402480e-01,\n",
      "         1.00794584e-01,  1.96333289e-01],\n",
      "       [-2.77594715e-01, -2.93118954e-01, -2.31935546e-01,\n",
      "        -2.94487566e-01, -1.09261379e-01, -5.95946051e-02,\n",
      "         1.08968347e-01, -9.36254039e-02],\n",
      "       [-3.41636479e-01, -1.94027618e-01,  2.72269964e-01,\n",
      "        -2.96397120e-01, -2.81416476e-01,  2.01846242e-01,\n",
      "        -5.67076132e-02, -3.54161412e-01],\n",
      "       [-2.49481499e-01,  1.15285292e-01,  1.26446769e-01,\n",
      "         3.63152213e-02,  4.27114338e-01, -3.47743630e-01,\n",
      "         3.16393316e-01, -7.66217932e-02],\n",
      "       [-1.26375109e-01, -2.03521058e-01, -2.42814291e-02,\n",
      "        -1.64555609e-01,  1.52541906e-01, -2.81451076e-01,\n",
      "        -2.60181516e-01, -2.43198931e-01],\n",
      "       [ 2.93645650e-01,  3.39436121e-02, -4.54101749e-02,\n",
      "        -1.49828181e-01,  1.79246500e-01, -2.09762782e-01,\n",
      "        -2.05096498e-01, -2.93802321e-01],\n",
      "       [ 8.65017846e-02, -2.51379788e-01,  2.76403725e-01,\n",
      "        -1.61067605e-01,  9.07072946e-02,  3.92278790e-01,\n",
      "        -1.66284174e-01,  2.76441693e-01],\n",
      "       [ 3.28382999e-02,  6.30315244e-02,  6.66905791e-02,\n",
      "        -8.16740245e-02, -7.88424537e-02,  7.41411597e-02,\n",
      "        -3.34271491e-01, -1.09453991e-01]], dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(8,) dtype=float32, numpy=\n",
      "array([ 0.01761708,  0.01023471, -0.02845697, -0.01249391, -0.05448446,\n",
      "        0.00767804,  0.02487668,  0.07399876], dtype=float32)>, <tf.Variable 'dense_3/kernel:0' shape=(8, 2) dtype=float32, numpy=\n",
      "array([[-0.326584  , -0.5942191 ],\n",
      "       [-0.17711923,  0.61856145],\n",
      "       [-0.47910142, -0.2904749 ],\n",
      "       [-0.21959464, -0.61363304],\n",
      "       [ 0.4392859 , -0.29264832],\n",
      "       [ 0.27541885,  0.40707937],\n",
      "       [ 0.06323527, -0.6323439 ],\n",
      "       [ 0.61261994, -0.10671211]], dtype=float32)>, <tf.Variable 'dense_3/bias:0' shape=(2,) dtype=float32, numpy=array([-0.04615164,  0.04615161], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48836675, 0.5116333 ],\n",
       "       [0.5013016 , 0.49869844],\n",
       "       [0.4916941 , 0.5083059 ],\n",
       "       [0.4916941 , 0.5083059 ],\n",
       "       [0.50001127, 0.4999887 ],\n",
       "       [0.4812158 , 0.5187842 ],\n",
       "       [0.49010134, 0.5098986 ],\n",
       "       [0.4916941 , 0.5083059 ],\n",
       "       [0.5013016 , 0.49869844],\n",
       "       [0.50526404, 0.49473593]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Hello Alex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
