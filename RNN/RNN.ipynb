{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/19\n",
      "10/20\n",
      "10/26\n",
      "10/27\n",
      "11/2\n",
      "11/3\n",
      "11/9\n",
      "11/10\n",
      "11/16\n",
      "11/17\n",
      "2900\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "File Reading\n",
    "\"\"\"\n",
    "a = []\n",
    "for i in range(14,32):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(file.name)\n",
    "    except:\n",
    "        print(\"10/\"+str(i))\n",
    "for i in range(1,22):\n",
    "    try:\n",
    "        for j in range(100):\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla\"+str(j)+\".txt\", mode='rb') as file:\n",
    "                try:\n",
    "                    a.append(str(file.read()))\n",
    "                except Exception as e:\n",
    "                    print(file.name)\n",
    "    except:\n",
    "        print(\"11/\"+str(i))\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700,)\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 100, 256)          439296    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 15,476,602\n",
      "Trainable params: 15,476,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neural Network Model Creation\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "x_train = np.array(a, dtype=np.str)\n",
    "x_train = x_train.astype(str)\n",
    "# print(x_train.shape)\n",
    "y_train = np.zeros(2700)+0.9\n",
    "print(y_train.shape)\n",
    "import tensorflow as tf\n",
    "embed_size = 300 \n",
    "max_features = 50000 \n",
    "maxlen = 100\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "model1 = tf.keras.Sequential()\n",
    "model1.add(Embedding(max_features, embed_size, input_length=maxlen))\n",
    "model1.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model1.add(GlobalMaxPool1D())\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(8, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(2,activation='softmax'))\n",
    "model1.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "model1.summary()\n",
    "x_trainR = np.array(x_train)[:2200]\n",
    "y_trainR = np.array(y_train)[:2200]\n",
    "x_test = np.array(x_train)[2200:]\n",
    "y_test = np.array(y_train)[2200:]\n",
    "x_train = x_trainR\n",
    "y_train = y_trainR\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Formats data labels\n",
    "\"\"\"\n",
    "def toFinal(a):\n",
    "    for i in range(len(a)):\n",
    "        if a[i] > 0:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1 1 1 ... 1 1 1]\n",
      "(1600,)\n",
      "(2200, 100)\n",
      "(1600, 100)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads and formats data labels\n",
    "\"\"\"\n",
    "y_train = []\n",
    "for i in range(14,32):\n",
    "    if(i != 19 and i!=20 and i!=26 and i!=27):\n",
    "        try:\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-10-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "                j = file.read().split(',')[1]\n",
    "                assert j is not None\n",
    "                j = j.replace('\\n','')\n",
    "                for _ in range(100):\n",
    "                    y_train.append(float(j))\n",
    "        except:\n",
    "            continue\n",
    "for i in range(1,22):\n",
    "    if(i != 2 and i!=3 and i!=9 and i!=10 and i!=16 and i!=17):\n",
    "        try:\n",
    "            with open(\"../TrainingData/TeslaTrainingData_2019-11-\"+str(i)+\"/Tesla.csv\") as file:\n",
    "                j = file.read().split(',')[1]\n",
    "                assert j is not None\n",
    "                j = j.replace('\\n','')\n",
    "                for _ in range(100):\n",
    "                    y_train.append(float(j))\n",
    "        except:\n",
    "            continue\n",
    "toFinal(y_train)\n",
    "print(y_train)\n",
    "y_train = np.array(y_train)\n",
    "print(y_train)\n",
    "y_test = y_train[2200:]\n",
    "y_train = y_train[:2200]\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "x_train = x_train[:1600]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(y_train))\n",
    "print(y_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1600 samples\n",
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 23s 14ms/sample - loss: 0.6278 - accuracy: 0.7244\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5755 - accuracy: 0.7494\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5819 - accuracy: 0.7475\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5763 - accuracy: 0.7475\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5745 - accuracy: 0.7481\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5711 - accuracy: 0.7494\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 20s 13ms/sample - loss: 0.5738 - accuracy: 0.7494\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 20s 12ms/sample - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5649 - accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 19s 12ms/sample - loss: 0.5591 - accuracy: 0.7494\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Trains Model\n",
    "\"\"\"\n",
    "history = model1.fit(x_train, y_train, epochs=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(x))\n",
    "    x =pad_sequences(tokenizer.texts_to_sequences(x), maxlen=maxlen)\n",
    "    return model1.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'embedding_7/embeddings:0' shape=(50000, 300) dtype=float32, numpy=\n",
      "array([[-0.00324253,  0.00367036, -0.06012659, ...,  0.02395823,\n",
      "        -0.01589693, -0.02220433],\n",
      "       [ 0.03264853, -0.04042051,  0.02365656, ..., -0.00375896,\n",
      "        -0.01809701,  0.04728856],\n",
      "       [-0.0075111 ,  0.08314388, -0.04958259, ..., -0.05833594,\n",
      "        -0.01143002,  0.03880596],\n",
      "       ...,\n",
      "       [-0.03846743, -0.01813477, -0.02916116, ..., -0.02910435,\n",
      "         0.04318285,  0.02199477],\n",
      "       [ 0.03141865,  0.02994383,  0.03526722, ...,  0.02763083,\n",
      "        -0.02455854,  0.00853541],\n",
      "       [ 0.03022898,  0.04083757,  0.03729815, ..., -0.01868541,\n",
      "         0.0251061 ,  0.03213276]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[ 0.01804008,  0.01948716, -0.072503  , ...,  0.07543774,\n",
      "        -0.03419763,  0.03013366],\n",
      "       [-0.01505032, -0.00891814, -0.04675484, ...,  0.06681027,\n",
      "         0.03331655,  0.033695  ],\n",
      "       [-0.03289101,  0.05317799, -0.02489413, ..., -0.01828043,\n",
      "        -0.10504992,  0.06458402],\n",
      "       ...,\n",
      "       [ 0.06375886,  0.02890871, -0.10188985, ..., -0.00483982,\n",
      "         0.02428271, -0.02083014],\n",
      "       [ 0.03128027, -0.04959466,  0.07667571, ...,  0.03035652,\n",
      "         0.04860416, -0.03298198],\n",
      "       [ 0.07438474,  0.01475993,  0.0995563 , ...,  0.07346594,\n",
      "        -0.10030717, -0.09229256]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[ 0.0284108 ,  0.05256992, -0.07405512, ...,  0.06151636,\n",
      "        -0.01031218, -0.01294132],\n",
      "       [ 0.06048728, -0.03929256,  0.05631687, ...,  0.05072338,\n",
      "         0.09248278, -0.00716977],\n",
      "       [ 0.0377588 ,  0.02400843, -0.09443588, ...,  0.09318389,\n",
      "         0.09353751, -0.01335538],\n",
      "       ...,\n",
      "       [-0.04970143, -0.08325291, -0.03140657, ..., -0.04268293,\n",
      "        -0.03814761, -0.03466541],\n",
      "       [ 0.01242713,  0.00389027,  0.0250969 , ...,  0.00656395,\n",
      "        -0.05372413,  0.04315615],\n",
      "       [-0.01483012, -0.07683308, -0.02325317, ..., -0.01976029,\n",
      "         0.00462992,  0.01202447]], dtype=float32)>, <tf.Variable 'bidirectional_3/forward_lstm_3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([ 1.2431190e-02, -1.0112032e-02,  1.7483598e-02,  1.3584562e-02,\n",
      "       -5.2641734e-02, -9.1557084e-03, -9.4356304e-03,  1.7073806e-02,\n",
      "       -3.6685963e-03, -2.1430064e-02,  7.1228170e-03,  4.2659283e-02,\n",
      "        2.4697714e-02,  2.0296166e-02, -4.5919813e-02,  1.2441099e-02,\n",
      "       -1.1678963e-02, -1.4613081e-02,  4.4771187e-02, -6.2467651e-03,\n",
      "       -1.0108653e-02,  2.0521250e-02,  2.0133760e-02,  4.7439512e-02,\n",
      "        1.0262745e-02,  1.9627162e-04, -2.9223189e-02,  1.6293498e-02,\n",
      "       -1.7195936e-02, -3.7010238e-02, -4.1183103e-02,  4.7737421e-03,\n",
      "       -4.9194988e-02, -6.3959695e-02,  6.7070534e-04,  2.1393368e-02,\n",
      "        1.3766479e-02,  3.0665470e-02,  1.1075735e-02, -1.2798849e-02,\n",
      "       -2.6325822e-02, -2.3161290e-02,  1.6000502e-02, -1.7723512e-02,\n",
      "       -1.8726652e-02, -1.9227806e-02, -6.0696803e-02,  2.2773784e-02,\n",
      "        1.4903933e-03, -8.3471544e-02, -7.9479138e-04,  3.5337519e-03,\n",
      "        1.2337193e-03,  8.8637052e-03,  2.6383167e-02, -1.0999009e-02,\n",
      "       -1.6626632e-02, -7.9299631e-03,  3.1966127e-02, -4.0715847e-02,\n",
      "       -3.4027882e-02,  2.8865941e-02, -2.9714447e-02,  5.3946201e-02,\n",
      "        3.4130432e-02,  5.5967614e-02, -3.1171381e-03,  3.4568261e-02,\n",
      "       -2.9586425e-02,  2.6473794e-03,  1.9459691e-02, -1.1189830e-02,\n",
      "        4.5516193e-02, -2.8239973e-03, -2.5080029e-02,  3.7081458e-02,\n",
      "       -7.1054385e-03,  3.3148192e-02,  3.3393349e-02,  5.3061832e-02,\n",
      "       -1.1741206e-02,  1.3412362e-02,  1.5550664e-03, -8.3962269e-03,\n",
      "       -3.6571909e-02, -1.3373406e-02, -1.3757668e-03, -1.1614214e-02,\n",
      "       -3.3557788e-02, -4.2106979e-02,  2.5448192e-02, -7.5439159e-03,\n",
      "        3.1525403e-02, -6.3628335e-03, -1.6777490e-03,  1.9791743e-03,\n",
      "       -3.6176888e-03,  3.1620946e-02, -7.2918743e-02,  6.1204676e-03,\n",
      "        2.2807524e-02, -2.7423928e-02, -1.0836140e-02, -3.2951385e-02,\n",
      "        9.8715564e-03,  1.4864003e-02,  8.5060783e-03, -5.3113211e-02,\n",
      "        1.3072736e-02, -1.8985413e-02, -1.2729343e-02, -3.0244810e-03,\n",
      "        1.9455861e-02,  2.2731552e-02,  1.4178769e-02, -9.1672363e-03,\n",
      "       -3.1708766e-02,  4.4156604e-02,  8.8331178e-03,  9.5880181e-03,\n",
      "        7.8803718e-02, -4.4011891e-02, -3.7786193e-02, -4.9143441e-02,\n",
      "        1.3077669e-02, -3.3489312e-03,  1.5545190e-02,  6.4173189e-04,\n",
      "        1.0071507e+00,  9.8103482e-01,  1.0211889e+00,  1.0238953e+00,\n",
      "        9.4274127e-01,  1.0249286e+00,  9.5411521e-01,  1.0174425e+00,\n",
      "        1.0062462e+00,  9.8037726e-01,  1.0200036e+00,  1.0262630e+00,\n",
      "        1.0216334e+00,  1.0237240e+00,  9.7444868e-01,  1.0013041e+00,\n",
      "        9.9033850e-01,  9.9230456e-01,  1.0416100e+00,  9.9892157e-01,\n",
      "        9.9358952e-01,  1.0108218e+00,  1.0141859e+00,  1.0437448e+00,\n",
      "        9.9252480e-01,  1.0026884e+00,  1.0073992e+00,  1.0177360e+00,\n",
      "        9.9458182e-01,  9.9160635e-01,  9.6896785e-01,  9.9359208e-01,\n",
      "        9.5195895e-01,  9.2258328e-01,  9.9682325e-01,  1.0249615e+00,\n",
      "        1.0131807e+00,  9.8251086e-01,  1.0091735e+00,  9.8432910e-01,\n",
      "        9.8531657e-01,  1.0019906e+00,  1.0158862e+00,  1.0043006e+00,\n",
      "        9.8150003e-01,  1.0019497e+00,  9.6638399e-01,  1.0188193e+00,\n",
      "        1.0084031e+00,  9.1501319e-01,  1.0089155e+00,  9.9641597e-01,\n",
      "        1.0157610e+00,  1.0108253e+00,  1.0222584e+00,  9.8492879e-01,\n",
      "        9.9615568e-01,  9.9369949e-01,  1.0340210e+00,  9.6826237e-01,\n",
      "        9.7645462e-01,  1.0280535e+00,  9.8032558e-01,  1.0471739e+00,\n",
      "        1.0083159e+00,  1.0535830e+00,  1.0055898e+00,  1.0298227e+00,\n",
      "        9.9327397e-01,  1.0022010e+00,  1.0275439e+00,  9.9191034e-01,\n",
      "        1.0072396e+00,  1.0034894e+00,  9.8881662e-01,  1.0255878e+00,\n",
      "        9.8752850e-01,  1.0289940e+00,  1.0188637e+00,  1.0297500e+00,\n",
      "        9.7867513e-01,  1.0251025e+00,  1.0148580e+00,  9.9745882e-01,\n",
      "        9.6407294e-01,  9.8699069e-01,  9.9896401e-01,  1.0055953e+00,\n",
      "        9.6937466e-01,  9.8247683e-01,  1.0264611e+00,  9.9050194e-01,\n",
      "        1.0147595e+00,  1.0098311e+00,  1.0021279e+00,  9.9649620e-01,\n",
      "        1.0099286e+00,  1.0169716e+00,  9.6147174e-01,  1.0063335e+00,\n",
      "        1.0173017e+00,  9.8406857e-01,  9.8643726e-01,  9.7254646e-01,\n",
      "        1.0097117e+00,  1.0208905e+00,  1.0178983e+00,  9.5759523e-01,\n",
      "        1.0199736e+00,  9.9798632e-01,  9.9160570e-01,  1.0032781e+00,\n",
      "        1.0281132e+00,  1.0274082e+00,  1.0184666e+00,  1.0008215e+00,\n",
      "        9.8350048e-01,  1.0446430e+00,  1.0082721e+00,  1.0040600e+00,\n",
      "        1.0554239e+00,  9.6513498e-01,  9.7979611e-01,  9.6535933e-01,\n",
      "        1.0106498e+00,  9.8643947e-01,  1.0223472e+00,  1.0045313e+00,\n",
      "        1.5178819e-05,  3.0158451e-02, -2.7098237e-02,  1.8486982e-02,\n",
      "       -2.6573064e-03, -1.6273463e-02, -3.4310512e-02,  1.4177796e-03,\n",
      "        5.3040953e-03, -9.4522489e-03,  9.1607133e-03, -3.5503402e-03,\n",
      "        1.9690180e-02, -2.3124956e-03, -1.4462730e-02,  1.1551260e-02,\n",
      "       -9.1881230e-03, -4.2043235e-03,  1.4433237e-03,  6.7467097e-04,\n",
      "       -1.6771279e-02,  1.5365555e-02, -2.8040076e-02,  3.1880096e-02,\n",
      "        6.9069066e-03, -1.6396925e-02, -2.8623154e-02,  1.8997453e-02,\n",
      "       -3.1423431e-03, -2.4116440e-02, -2.4812233e-03, -1.2284489e-02,\n",
      "       -9.3966546e-03, -6.5055452e-03,  3.1964928e-03,  1.8304104e-02,\n",
      "        2.6333254e-02, -1.0242154e-03,  8.5783973e-03,  1.1490056e-02,\n",
      "       -1.3456704e-02, -4.8612915e-03, -1.8180124e-02,  5.6565567e-03,\n",
      "       -1.9584179e-02, -1.4645649e-02, -2.0507663e-02,  1.6650096e-02,\n",
      "        6.8980306e-03, -7.8314096e-03,  1.1525601e-03, -1.7937256e-02,\n",
      "        5.9455880e-03,  2.3338629e-02,  2.0795744e-02,  2.7840849e-02,\n",
      "        1.9319227e-02, -1.4220668e-02,  1.2945459e-02, -9.9467710e-03,\n",
      "       -6.2655997e-03,  2.7326031e-02, -1.8911300e-02, -1.9087195e-03,\n",
      "       -2.5793320e-02, -1.0854386e-03,  1.7663185e-02,  2.0236334e-02,\n",
      "       -9.7897388e-03, -1.7290605e-02,  2.0808583e-02,  1.3434709e-02,\n",
      "       -1.6518790e-02, -1.0947671e-02, -9.9814218e-03,  6.2734126e-03,\n",
      "       -5.5762324e-03,  2.2206614e-02, -4.7969993e-02,  6.7637032e-03,\n",
      "       -2.1133864e-02,  2.1315096e-02, -1.1440728e-02, -6.9249282e-03,\n",
      "       -9.1330288e-03,  1.3184148e-03,  5.6936368e-03, -1.2698438e-02,\n",
      "        6.0501131e-03, -2.7721817e-02,  2.3028711e-02,  2.9835720e-03,\n",
      "       -8.5384622e-03, -3.0413242e-03,  6.4304015e-03, -6.5735001e-03,\n",
      "        8.7577635e-03, -9.8305307e-03, -2.8263787e-02, -6.1991937e-03,\n",
      "        6.1455569e-03, -4.1235136e-03, -1.8977825e-02, -1.9884225e-02,\n",
      "        4.1081444e-03,  1.2492280e-02,  2.2383877e-03, -2.0576786e-02,\n",
      "       -1.4886438e-02, -2.3469800e-02, -3.8359717e-02, -1.0687943e-03,\n",
      "       -3.3789654e-03,  1.5622165e-02,  1.7213769e-02, -3.6912621e-03,\n",
      "       -2.0872058e-02, -6.4904862e-03,  3.2643814e-02, -8.6510526e-03,\n",
      "        1.4572211e-02, -1.2415569e-02,  2.8291247e-03, -2.7092338e-02,\n",
      "       -8.5400725e-03,  6.7110853e-03,  1.8486960e-02, -5.2432441e-03,\n",
      "        1.3760181e-02, -2.1352857e-02,  2.9502012e-04, -2.0330934e-02,\n",
      "       -5.8433317e-02, -2.7365113e-02, -1.2235370e-02, -2.0590096e-03,\n",
      "       -1.5985349e-02, -3.2224186e-02, -1.0341755e-02, -8.3754882e-03,\n",
      "       -1.1433344e-02,  1.0106359e-02, -5.2087672e-02, -6.7929188e-03,\n",
      "       -4.2509899e-02, -2.4886480e-02,  9.3045375e-05, -1.7670415e-02,\n",
      "       -2.9323515e-02, -1.5795277e-02, -2.8785441e-02,  2.6376482e-02,\n",
      "       -1.8852456e-02, -4.4479303e-02, -2.8625568e-02, -1.1676394e-02,\n",
      "       -3.1454388e-02, -4.2573594e-02, -4.5344595e-02,  2.4712963e-03,\n",
      "       -5.1076453e-02, -6.5804087e-02,  6.8125501e-03,  1.3139793e-03,\n",
      "       -3.7775433e-03, -3.1507458e-03, -1.8315390e-03, -1.3706179e-02,\n",
      "       -3.4908164e-02, -4.3973878e-02,  4.4904132e-03,  3.3266668e-03,\n",
      "       -1.6099244e-02, -3.4966219e-02, -5.9693821e-02,  3.6224383e-03,\n",
      "       -1.9006710e-02, -9.7178921e-02, -2.1596435e-02, -2.2633681e-02,\n",
      "        4.3337076e-04, -6.2467181e-03, -1.6737008e-02, -1.0597680e-02,\n",
      "       -2.1439942e-02, -8.3456086e-03, -2.2279301e-03, -4.9251191e-02,\n",
      "       -7.5878814e-02,  1.6557120e-02, -4.4318553e-02,  3.2409016e-02,\n",
      "        3.5248283e-02,  1.9983377e-02, -1.2077928e-02,  3.1011745e-03,\n",
      "       -5.3088415e-02, -1.9192118e-02, -1.0461756e-02, -1.2722925e-02,\n",
      "        1.4707902e-02, -3.2328986e-02, -2.7959535e-02, -1.4216850e-02,\n",
      "       -1.9353090e-02,  3.9996626e-04,  1.1356452e-02,  3.8347632e-02,\n",
      "       -1.1423570e-02, -1.1070929e-03,  1.2995344e-02, -2.7590290e-02,\n",
      "       -5.4670617e-02, -2.0726904e-02, -3.3932727e-02, -2.9779080e-02,\n",
      "       -4.6413150e-02, -4.5075379e-02, -5.2471333e-03, -2.3664674e-02,\n",
      "       -2.6272506e-02, -5.2211192e-03, -1.1310275e-02, -1.3792203e-02,\n",
      "       -2.3434982e-02,  1.7971734e-02, -8.2960099e-02, -1.9884186e-02,\n",
      "        3.4004435e-02, -3.8383618e-02, -4.4478960e-02, -3.9709203e-02,\n",
      "        2.5710911e-03, -7.1904995e-03, -3.3137633e-04, -8.0841497e-02,\n",
      "       -1.3018039e-02, -3.1822566e-02,  8.8516427e-03, -8.2639931e-03,\n",
      "       -2.8000972e-03, -1.2135145e-02, -1.1054553e-02, -2.3791891e-02,\n",
      "       -3.0232565e-02,  1.3153932e-02, -9.9040875e-03, -2.4814192e-02,\n",
      "        7.2321355e-02, -4.2530134e-02, -5.3533103e-02, -7.0938312e-02,\n",
      "       -3.3416346e-02, -7.7248160e-03, -1.6094790e-03, -1.0540274e-02],\n",
      "      dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/kernel:0' shape=(300, 512) dtype=float32, numpy=\n",
      "array([[ 5.88628389e-02,  4.69365083e-02,  4.41567488e-02, ...,\n",
      "        -1.10037345e-02, -1.48431128e-02, -3.93137224e-02],\n",
      "       [ 6.26612753e-02, -7.88254961e-02, -5.58951404e-03, ...,\n",
      "         3.80963236e-02, -6.89453408e-02, -3.51083986e-02],\n",
      "       [-1.48702757e-02,  1.35683259e-02, -2.68204901e-02, ...,\n",
      "         5.63878678e-02, -5.17194718e-02, -5.24606183e-02],\n",
      "       ...,\n",
      "       [-1.04131876e-02,  8.25713798e-02,  7.19058514e-02, ...,\n",
      "         7.05569535e-02, -3.67644466e-02, -2.79760659e-02],\n",
      "       [-1.33077009e-02, -2.03625690e-02, -1.06623694e-01, ...,\n",
      "        -9.44697857e-02, -6.40751095e-05, -6.15171790e-02],\n",
      "       [-6.68501481e-02,  4.82157953e-02, -1.59958247e-02, ...,\n",
      "        -9.55942422e-02, -1.25154741e-02, -1.64901596e-02]], dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/recurrent_kernel:0' shape=(128, 512) dtype=float32, numpy=\n",
      "array([[-0.0286651 , -0.04903264,  0.00781622, ...,  0.01260801,\n",
      "         0.00257866, -0.0549661 ],\n",
      "       [-0.03256062,  0.01014961,  0.00094636, ..., -0.00971371,\n",
      "        -0.03752475, -0.02329709],\n",
      "       [-0.07080372, -0.03201241,  0.03084266, ...,  0.02307616,\n",
      "         0.00465491,  0.04621208],\n",
      "       ...,\n",
      "       [-0.01431343, -0.03829563, -0.02093072, ..., -0.07028785,\n",
      "        -0.00827062, -0.06396474],\n",
      "       [ 0.0092423 ,  0.04701083,  0.05873877, ...,  0.07806497,\n",
      "        -0.03130394,  0.00261101],\n",
      "       [-0.07695752,  0.03861802, -0.08654077, ..., -0.05567205,\n",
      "        -0.01925897, -0.02245463]], dtype=float32)>, <tf.Variable 'bidirectional_3/backward_lstm_3/bias:0' shape=(512,) dtype=float32, numpy=\n",
      "array([-8.33512098e-03,  7.97486305e-03, -7.33422302e-03, -4.86115599e-03,\n",
      "        3.69289406e-02,  3.06969490e-02,  1.04932860e-03, -3.23888473e-02,\n",
      "       -4.55927476e-02,  7.02319713e-03, -6.63073326e-04,  4.17068861e-02,\n",
      "       -4.87339571e-02, -2.56592757e-03,  3.01362537e-02, -1.19292438e-02,\n",
      "       -2.04836614e-02,  9.71354358e-03, -5.31419776e-02,  1.94625109e-02,\n",
      "        2.10671891e-02, -3.46361883e-02,  2.92557366e-02,  5.74942082e-02,\n",
      "        1.84390065e-03,  6.85550366e-03, -1.86848957e-02, -3.64810005e-02,\n",
      "        2.11279504e-02, -1.01380190e-02,  1.64152905e-02,  3.17939818e-02,\n",
      "        3.73997018e-02, -2.25455370e-02, -2.82984730e-02, -1.17693078e-02,\n",
      "        1.50661785e-02, -3.63809057e-02, -1.10992324e-02,  3.54673006e-02,\n",
      "       -1.04576526e-02,  3.35441856e-03,  2.31372416e-02,  8.28777906e-03,\n",
      "       -6.28952775e-03, -2.07590107e-02, -5.46557084e-02,  1.28233628e-02,\n",
      "        2.27027703e-02,  1.27517795e-02,  5.37918182e-03, -2.72823237e-02,\n",
      "        3.88137111e-03, -1.81334093e-02, -2.13570371e-02, -2.37389375e-02,\n",
      "       -1.29473116e-02,  1.69578586e-02, -3.24797332e-02,  3.00334729e-02,\n",
      "        1.92454383e-02, -3.13251801e-02, -1.26996869e-02, -2.28355103e-03,\n",
      "       -3.63134183e-02,  1.46144899e-02, -6.25381693e-02,  1.96083635e-02,\n",
      "       -8.02248344e-03, -4.31391820e-02, -6.90414896e-03, -6.43078014e-02,\n",
      "        2.71899570e-02, -2.55775582e-02,  8.61964282e-03, -3.77383940e-02,\n",
      "       -2.33188900e-03,  3.47020291e-02,  1.05911279e-02, -4.42984141e-03,\n",
      "       -6.20966544e-03, -1.56199317e-02, -2.66273059e-02,  4.11969237e-02,\n",
      "        2.38937102e-02, -2.96510588e-02, -1.27110155e-02,  3.96450423e-02,\n",
      "       -5.08417562e-03, -4.93031256e-02, -9.05036740e-03,  3.02185584e-02,\n",
      "        3.19715813e-02, -3.42346355e-02,  2.09875647e-02,  9.72497463e-03,\n",
      "        1.25818811e-02,  6.35685697e-02, -7.81762879e-03, -4.69925161e-03,\n",
      "        1.41214684e-03,  1.50330281e-02,  1.90341622e-02, -2.69961543e-02,\n",
      "        9.68353078e-03,  1.59673560e-02, -3.15396413e-02,  4.83686244e-03,\n",
      "       -3.28390561e-02,  1.42011307e-02,  6.64556911e-03, -3.40688303e-02,\n",
      "       -1.72793362e-02, -2.59948103e-03, -4.07361006e-03, -1.67524219e-02,\n",
      "        1.82900039e-04,  2.97823362e-02, -2.01278813e-02, -8.74822028e-03,\n",
      "       -8.80005304e-03, -1.50490329e-02, -3.54634225e-02, -2.83866581e-02,\n",
      "        7.33989431e-03,  3.58787626e-02, -2.97170971e-02, -2.79687950e-03,\n",
      "        9.73512530e-01,  1.00950098e+00,  9.86511230e-01,  9.95592535e-01,\n",
      "        1.00426269e+00,  1.02023327e+00,  1.00172246e+00,  9.63411152e-01,\n",
      "        9.54895556e-01,  9.99572754e-01,  9.97105539e-01,  1.01693094e+00,\n",
      "        9.56034720e-01,  9.94114161e-01,  1.02765810e+00,  9.88348722e-01,\n",
      "        9.72434998e-01,  1.01791131e+00,  9.59031940e-01,  1.01846945e+00,\n",
      "        9.91060913e-01,  9.69562054e-01,  1.04398918e+00,  1.01016653e+00,\n",
      "        9.83699083e-01,  1.00459063e+00,  9.72054422e-01,  9.54487562e-01,\n",
      "        1.03873336e+00,  9.92261708e-01,  1.02424085e+00,  9.62438285e-01,\n",
      "        1.03528726e+00,  9.77868736e-01,  9.66460288e-01,  1.00410652e+00,\n",
      "        1.00050056e+00,  9.61201608e-01,  9.87831652e-01,  1.01442802e+00,\n",
      "        9.87994432e-01,  9.96490240e-01,  1.02589333e+00,  1.00072885e+00,\n",
      "        9.88470614e-01,  9.84558523e-01,  9.68381882e-01,  1.00237465e+00,\n",
      "        1.00820327e+00,  9.84651208e-01,  1.00145876e+00,  9.47625160e-01,\n",
      "        9.62741017e-01,  9.84600186e-01,  9.86243129e-01,  9.79376912e-01,\n",
      "        9.93057311e-01,  1.00839138e+00,  9.77828979e-01,  1.02559936e+00,\n",
      "        1.03972876e+00,  9.81912673e-01,  9.94516730e-01,  9.93693769e-01,\n",
      "        9.57909763e-01,  1.00650883e+00,  9.57496822e-01,  9.91057217e-01,\n",
      "        9.46760297e-01,  9.46699500e-01,  9.63814139e-01,  9.55062807e-01,\n",
      "        1.03448164e+00,  9.77056861e-01,  9.97413933e-01,  9.76802945e-01,\n",
      "        9.91667747e-01,  1.03977275e+00,  1.01338077e+00,  9.78978157e-01,\n",
      "        9.98594522e-01,  9.75786686e-01,  9.77330506e-01,  1.03837788e+00,\n",
      "        1.02253306e+00,  9.75504935e-01,  9.74819958e-01,  1.03851259e+00,\n",
      "        9.69816506e-01,  9.43604350e-01,  9.73167002e-01,  1.02169824e+00,\n",
      "        1.03641987e+00,  9.50884998e-01,  1.01354301e+00,  1.00388837e+00,\n",
      "        1.00552940e+00,  1.05284405e+00,  9.91557121e-01,  1.01162493e+00,\n",
      "        1.00026762e+00,  1.01735437e+00,  1.03722525e+00,  9.88178909e-01,\n",
      "        1.01955211e+00,  1.00618231e+00,  9.70790863e-01,  9.85349476e-01,\n",
      "        9.50659871e-01,  1.01358056e+00,  1.00060558e+00,  9.50753391e-01,\n",
      "        9.77999806e-01,  9.97565150e-01,  1.00731587e+00,  9.91735399e-01,\n",
      "        9.86537874e-01,  1.00133002e+00,  9.87860799e-01,  1.01223493e+00,\n",
      "        9.94172692e-01,  9.68551517e-01,  9.89082873e-01,  9.71505761e-01,\n",
      "        1.00708437e+00,  1.03507781e+00,  9.64270115e-01,  9.91688788e-01,\n",
      "       -2.53699371e-03,  4.30116393e-02, -4.32696007e-03,  3.30443420e-02,\n",
      "       -2.91596148e-02, -1.98336467e-02,  4.33976017e-02,  1.65608805e-02,\n",
      "       -3.15920860e-02,  4.03739363e-02,  2.04107109e-02, -2.31154393e-02,\n",
      "       -2.91645825e-02, -1.42226862e-02,  5.41625395e-02,  2.34256741e-02,\n",
      "       -2.43332684e-02, -3.80766280e-02, -1.37616117e-02,  3.97159941e-02,\n",
      "       -2.18526013e-02, -5.07264456e-04, -4.25928533e-02, -1.37339104e-02,\n",
      "        1.76710188e-02, -2.05825921e-02,  1.15421331e-02, -2.42955592e-02,\n",
      "        3.29417363e-02,  3.97112034e-02, -4.01654653e-02,  2.15116851e-02,\n",
      "        5.51543012e-02, -2.07992159e-02, -2.08118167e-02, -1.47420377e-03,\n",
      "       -1.21464897e-02, -9.76849440e-03,  1.13083012e-02,  5.24083199e-03,\n",
      "        1.00203305e-02, -5.07566668e-02,  4.19272147e-02,  4.36072685e-02,\n",
      "       -4.78620976e-02,  1.33658042e-02, -4.03070077e-02, -3.11110280e-02,\n",
      "       -1.29902726e-02, -3.23045142e-02, -8.55155755e-03, -2.36461852e-02,\n",
      "       -3.32877273e-03, -2.06187721e-02, -3.15023921e-02,  2.40400480e-03,\n",
      "       -2.03400082e-03,  1.45270340e-02,  2.78442316e-02,  4.77262102e-02,\n",
      "       -4.43915725e-02, -2.58187670e-02,  3.24456394e-02,  1.41599523e-02,\n",
      "       -1.79312527e-02,  2.01362558e-02,  4.20734659e-03,  2.78838500e-02,\n",
      "        1.63919199e-02, -1.79148056e-02,  9.59217083e-03, -9.90124047e-03,\n",
      "        4.50202636e-02, -1.16405981e-02, -2.27981247e-02, -3.74827944e-02,\n",
      "        3.14107873e-02, -4.66154376e-03, -3.15154046e-02, -1.44255310e-02,\n",
      "        1.16294175e-02, -6.91923080e-03,  1.85755044e-02,  4.93408218e-02,\n",
      "        3.89823429e-02,  1.24195684e-02, -7.91881792e-03,  4.14973013e-02,\n",
      "       -2.30551362e-02, -1.31664351e-02, -2.83832848e-02, -3.33685912e-02,\n",
      "       -4.42198068e-02, -1.97798125e-02, -2.94901710e-02,  3.99770923e-02,\n",
      "       -3.74919176e-02,  4.51527089e-02,  1.78019889e-02, -4.64775562e-02,\n",
      "        1.74469557e-02,  3.14503312e-02, -4.51214723e-02, -4.38982956e-02,\n",
      "       -4.47958298e-02,  2.04434879e-02, -1.62830800e-02,  1.36837792e-02,\n",
      "       -1.02459462e-02,  4.57990132e-02, -1.30733969e-02, -9.55855567e-03,\n",
      "        7.44959200e-03,  1.70616638e-02, -3.60042080e-02,  1.96412615e-02,\n",
      "        2.95433719e-02, -3.82381938e-02, -4.11899202e-02, -3.45919132e-02,\n",
      "        1.37828826e-03,  1.84262078e-02,  1.50047438e-02,  2.30367593e-02,\n",
      "       -2.89048348e-03,  3.93287465e-02, -1.75454803e-02,  2.00640634e-02,\n",
      "       -2.25650053e-02,  1.38747494e-03, -1.96372326e-02, -1.03036147e-02,\n",
      "        3.54950912e-02, -1.34513825e-02, -6.66065654e-03, -3.41706313e-02,\n",
      "       -4.51686308e-02, -1.97229013e-02, -4.40488942e-03,  1.28390966e-02,\n",
      "       -4.94570695e-02,  2.48615339e-04,  1.91576257e-02, -1.51321981e-02,\n",
      "       -2.72805039e-02, -7.94918835e-03, -4.85705584e-02, -7.51236361e-03,\n",
      "       -1.11256381e-02, -3.62316221e-02,  1.99444797e-02,  6.33364916e-02,\n",
      "        1.90461613e-02, -2.29085777e-02, -3.43871713e-02, -4.45524268e-02,\n",
      "       -8.86217225e-03, -2.30085030e-02,  3.42071359e-03,  2.84865908e-02,\n",
      "        7.73418741e-03, -3.53779793e-02, -3.11884340e-02, -2.18688976e-03,\n",
      "        1.80635378e-02, -5.09208329e-02, -2.09263358e-02,  3.12865488e-02,\n",
      "       -8.11879616e-03, -1.80236865e-02, -3.72673990e-03, -1.26340762e-02,\n",
      "       -3.17710638e-02, -1.86709128e-02, -6.12707697e-02, -7.87626579e-03,\n",
      "       -8.62744264e-03,  1.15604298e-02, -3.01057310e-03, -3.98922563e-02,\n",
      "       -9.99313220e-03, -1.60464626e-02, -4.50469404e-02, -2.51634661e-02,\n",
      "       -2.50275098e-02,  2.64404761e-03, -3.64100039e-02,  8.41988018e-04,\n",
      "       -4.29146364e-03, -6.25965223e-02, -1.88193657e-02, -2.21818667e-02,\n",
      "       -3.10502835e-02, -7.34991254e-03, -5.49790487e-02,  5.86342486e-03,\n",
      "       -4.35677171e-03, -4.79648598e-02, -8.83121137e-03, -5.39555252e-02,\n",
      "        1.69888493e-02, -3.20745781e-02, -2.04167776e-02, -3.23650986e-02,\n",
      "       -1.36619583e-02,  1.59337074e-02,  4.44960641e-03, -1.77152846e-02,\n",
      "       -2.21822243e-02, -2.34560557e-02, -3.82896513e-02, -4.61005955e-04,\n",
      "        4.96316375e-03, -2.31906623e-02, -2.97414660e-02, -9.27461591e-03,\n",
      "       -3.19862515e-02, -4.46071215e-02, -4.07988839e-02,  8.49728100e-03,\n",
      "        1.68211218e-02, -3.55660766e-02, -2.74051423e-03, -1.28538711e-02,\n",
      "       -1.50190089e-02,  1.01067275e-02, -1.97108947e-02, -1.60409007e-02,\n",
      "       -2.87012034e-03, -6.95908302e-03, -1.17331799e-02, -2.93608531e-02,\n",
      "       -7.84296542e-03,  1.44021595e-02, -3.39501910e-02, -1.54192708e-02,\n",
      "       -4.41962220e-02, -1.38626164e-02, -3.64051736e-03, -4.22497019e-02,\n",
      "       -1.91276204e-02, -9.26728453e-03, -1.71337668e-02, -9.18814074e-03,\n",
      "       -5.09929191e-03,  1.63337495e-02, -4.10433933e-02, -9.74091142e-03,\n",
      "       -2.25368775e-02, -1.20726442e-02, -6.11331910e-02, -3.27868536e-02,\n",
      "        6.56456547e-03, -2.94085185e-04, -4.86431010e-02, -6.23121858e-03],\n",
      "      dtype=float32)>, <tf.Variable 'dense_24/kernel:0' shape=(256, 128) dtype=float32, numpy=\n",
      "array([[-0.13006617,  0.09516411, -0.00720053, ..., -0.05343518,\n",
      "        -0.10076967, -0.06358624],\n",
      "       [-0.13275036, -0.0738579 , -0.02548079, ...,  0.0599743 ,\n",
      "        -0.12280567, -0.00708876],\n",
      "       [ 0.04719127,  0.03466055, -0.04759603, ..., -0.02693284,\n",
      "         0.01139071,  0.08684646],\n",
      "       ...,\n",
      "       [-0.01593268,  0.10606828,  0.07315188, ..., -0.05926647,\n",
      "        -0.12348939, -0.03429289],\n",
      "       [ 0.12187704,  0.07624057, -0.03272378, ...,  0.10623121,\n",
      "         0.04546306, -0.11296906],\n",
      "       [-0.14684694,  0.04143632,  0.05212913, ..., -0.05893552,\n",
      "         0.01623026,  0.05078993]], dtype=float32)>, <tf.Variable 'dense_24/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([-0.00041983, -0.00414655,  0.01713678, -0.01131532, -0.0076308 ,\n",
      "       -0.01046712, -0.01341966, -0.0180551 , -0.01120328, -0.01624564,\n",
      "        0.00901802, -0.01047497, -0.01353426,  0.018068  ,  0.03070172,\n",
      "       -0.00577331, -0.00782396, -0.00559047, -0.00939253,  0.00457352,\n",
      "        0.01249017, -0.00660733, -0.00639366, -0.01670746, -0.01012981,\n",
      "       -0.00995936,  0.00833298, -0.01679727, -0.0131797 , -0.01206552,\n",
      "        0.02117906,  0.01194379, -0.00550881,  0.03751231,  0.00388811,\n",
      "       -0.00400496,  0.02598154,  0.0020437 , -0.00102105, -0.01190272,\n",
      "        0.00218804,  0.00076118, -0.03361044, -0.00079496,  0.03083154,\n",
      "       -0.01319756, -0.01720284, -0.00909862,  0.00931836, -0.0150983 ,\n",
      "        0.01931562, -0.00701136, -0.01410496,  0.03049491, -0.00948542,\n",
      "       -0.01512067, -0.01724085, -0.01190329, -0.00855346, -0.00832447,\n",
      "       -0.01440921,  0.00363096, -0.00832225, -0.01131606, -0.00345712,\n",
      "        0.01102411, -0.00166868, -0.02745673, -0.00910996, -0.01749071,\n",
      "       -0.00747876,  0.00245797, -0.00966285, -0.01157168, -0.0048949 ,\n",
      "       -0.01116489, -0.01696709, -0.01740434, -0.01948044,  0.00852429,\n",
      "        0.0169531 , -0.00557182,  0.0062268 , -0.01354114, -0.00981177,\n",
      "       -0.01073267,  0.02614938, -0.01302954, -0.0010218 , -0.01493512,\n",
      "       -0.01110595, -0.01219692, -0.00523264, -0.01518933,  0.0047763 ,\n",
      "       -0.01422925, -0.00022092, -0.02035985, -0.02335028, -0.00901029,\n",
      "       -0.02052135,  0.01864459, -0.01695031,  0.01006641, -0.01710827,\n",
      "       -0.01057228, -0.00994925, -0.00579873, -0.00536597, -0.01273302,\n",
      "       -0.01228501, -0.00821154, -0.01124386, -0.00691182,  0.01693639,\n",
      "       -0.00474085,  0.01088484, -0.01402822,  0.0009223 , -0.01154275,\n",
      "       -0.0184159 , -0.01000576,  0.0023873 , -0.0063971 , -0.00802738,\n",
      "       -0.00589593, -0.00771184, -0.01437028], dtype=float32)>, <tf.Variable 'dense_25/kernel:0' shape=(128, 32) dtype=float32, numpy=\n",
      "array([[-0.18518227,  0.00482389,  0.0066375 , ...,  0.1570676 ,\n",
      "         0.05324943,  0.06042574],\n",
      "       [-0.12968944, -0.09853145,  0.0228277 , ..., -0.14701726,\n",
      "         0.13814008, -0.01524549],\n",
      "       [ 0.13339919, -0.1140583 , -0.10467239, ..., -0.05459103,\n",
      "        -0.15629227, -0.18782108],\n",
      "       ...,\n",
      "       [-0.07108871,  0.17720783, -0.15839049, ..., -0.12531292,\n",
      "         0.02599813, -0.04559205],\n",
      "       [-0.17919612,  0.02971732, -0.12303928, ...,  0.15656245,\n",
      "        -0.01362201,  0.09586915],\n",
      "       [ 0.10627534, -0.1395828 , -0.16667329, ...,  0.01995615,\n",
      "         0.06475025, -0.14561482]], dtype=float32)>, <tf.Variable 'dense_25/bias:0' shape=(32,) dtype=float32, numpy=\n",
      "array([-0.01256547, -0.01905565, -0.01187342, -0.02649223, -0.01718165,\n",
      "        0.04962672, -0.02586821,  0.01976067, -0.0093164 , -0.01732573,\n",
      "       -0.00152564,  0.04905234, -0.00041491, -0.01642797, -0.01790086,\n",
      "       -0.02082093, -0.00358219, -0.01676621, -0.0174301 , -0.02085097,\n",
      "        0.01820133,  0.02306103,  0.00187305, -0.01775922, -0.01480482,\n",
      "       -0.01952915, -0.02486924,  0.00197677, -0.02080599, -0.01435244,\n",
      "        0.0063974 , -0.01686116], dtype=float32)>, <tf.Variable 'dense_26/kernel:0' shape=(32, 8) dtype=float32, numpy=\n",
      "array([[ 0.38506997, -0.0184406 , -0.22830404, -0.06772864,  0.26620775,\n",
      "         0.31994203, -0.23009548,  0.12773411],\n",
      "       [ 0.23087394,  0.17154044,  0.32848036, -0.27807844, -0.15209311,\n",
      "         0.33388814, -0.24543023,  0.06564847],\n",
      "       [-0.3424301 ,  0.38391134,  0.08563265, -0.2610494 , -0.2669058 ,\n",
      "         0.3268007 ,  0.37398568, -0.08496015],\n",
      "       [ 0.27756318, -0.32468244, -0.38373938, -0.16070609,  0.27978343,\n",
      "         0.11268468,  0.08924531,  0.2798363 ],\n",
      "       [ 0.15440331, -0.02102741,  0.14693393, -0.24356887,  0.02399703,\n",
      "        -0.13976687, -0.18685785, -0.08957007],\n",
      "       [-0.05886135,  0.35993573, -0.2964175 , -0.40307996,  0.3396921 ,\n",
      "        -0.02970642,  0.20637318, -0.1405802 ],\n",
      "       [ 0.07375395, -0.16127145,  0.05018022, -0.23685488,  0.28893238,\n",
      "         0.16612762,  0.23831035,  0.14058498],\n",
      "       [-0.3472901 , -0.16786082, -0.0703866 ,  0.01298057,  0.17847084,\n",
      "        -0.14936309, -0.04303606,  0.04565458],\n",
      "       [ 0.10416568, -0.2664732 ,  0.38047   ,  0.22555663, -0.15003516,\n",
      "        -0.0934734 , -0.09347206,  0.2160786 ],\n",
      "       [-0.09872141,  0.22246295,  0.23690955, -0.07470017, -0.06923933,\n",
      "         0.3015728 ,  0.1859446 ,  0.08086071],\n",
      "       [-0.17197037,  0.358375  ,  0.02614345,  0.16900828,  0.3694657 ,\n",
      "        -0.37795103,  0.0252799 ,  0.15925787],\n",
      "       [-0.3484272 ,  0.35846734, -0.22471578,  0.26350436,  0.10564402,\n",
      "         0.1135391 ,  0.25277308, -0.20418228],\n",
      "       [-0.31278604, -0.22444338,  0.3357284 , -0.18627144, -0.23111947,\n",
      "        -0.33969396, -0.1949117 , -0.34684947],\n",
      "       [-0.21585429, -0.22780655,  0.06109716, -0.18107362, -0.1771238 ,\n",
      "        -0.27912503, -0.17410511, -0.42024848],\n",
      "       [ 0.32089376,  0.18165225,  0.13870235,  0.13433841,  0.01642465,\n",
      "         0.3377197 ,  0.14018892,  0.14506003],\n",
      "       [-0.03046188,  0.04493518,  0.21207558,  0.16342829,  0.05547534,\n",
      "        -0.13890865,  0.04288707,  0.20338844],\n",
      "       [ 0.11413649,  0.27215254, -0.04243689,  0.05223799, -0.11119179,\n",
      "         0.29741055,  0.09224538, -0.30061585],\n",
      "       [ 0.1426551 ,  0.2597803 , -0.20964555, -0.06292255,  0.25263405,\n",
      "         0.03206338, -0.1733697 ,  0.23309743],\n",
      "       [-0.32364476,  0.07523435, -0.16997041, -0.05497584, -0.09398004,\n",
      "        -0.15529113,  0.41926095,  0.16076174],\n",
      "       [ 0.1975643 ,  0.3121036 ,  0.04062464, -0.16341147,  0.2460551 ,\n",
      "        -0.3087972 , -0.12069652,  0.18107244],\n",
      "       [ 0.21310751, -0.00215604,  0.01807926,  0.32038724,  0.23942025,\n",
      "        -0.10091512, -0.01931971, -0.15029585],\n",
      "       [-0.22236492,  0.3454141 , -0.15376176, -0.10642701, -0.23425654,\n",
      "        -0.19641747,  0.23222415, -0.22753027],\n",
      "       [ 0.19247523,  0.33956873, -0.11823554, -0.18230009, -0.3595003 ,\n",
      "         0.19456325,  0.3273854 , -0.28143153],\n",
      "       [ 0.34905043, -0.32418597,  0.31965047, -0.13947372, -0.04930744,\n",
      "         0.03553143, -0.05708885, -0.22453569],\n",
      "       [ 0.05392549, -0.29525873, -0.38564366,  0.34552816,  0.30555943,\n",
      "        -0.01244244, -0.20548682,  0.2881468 ],\n",
      "       [ 0.1636536 ,  0.15891352,  0.18560915, -0.34251514, -0.28587517,\n",
      "        -0.33163926, -0.1737051 , -0.0611258 ],\n",
      "       [-0.07873309, -0.25020793, -0.09281681, -0.3113173 , -0.2388101 ,\n",
      "        -0.1185776 , -0.11666331,  0.14979304],\n",
      "       [ 0.24174805,  0.23532446, -0.35249558, -0.1329246 ,  0.30071667,\n",
      "        -0.29400605, -0.24810119,  0.2774692 ],\n",
      "       [ 0.35626408, -0.17711242, -0.17159939,  0.37303907, -0.22738156,\n",
      "        -0.16809006,  0.29312143,  0.2330301 ],\n",
      "       [ 0.26020604,  0.34012508,  0.3408834 , -0.06149133,  0.37292802,\n",
      "        -0.28234595, -0.3464892 ,  0.268103  ],\n",
      "       [-0.05755729,  0.22664033,  0.2552031 ,  0.19948266,  0.34996265,\n",
      "        -0.11027125,  0.05009927,  0.01053391],\n",
      "       [ 0.01907756,  0.34599635, -0.10505089, -0.12904279,  0.04390148,\n",
      "        -0.05469367, -0.20431982,  0.25443402]], dtype=float32)>, <tf.Variable 'dense_26/bias:0' shape=(8,) dtype=float32, numpy=\n",
      "array([-0.0477405 ,  0.10916641, -0.0404043 ,  0.09631067,  0.07944863,\n",
      "       -0.05383665,  0.13090086, -0.05114203], dtype=float32)>, <tf.Variable 'dense_27/kernel:0' shape=(8, 2) dtype=float32, numpy=\n",
      "array([[ 0.32449657, -0.23809686],\n",
      "       [-0.71342736, -0.6491518 ],\n",
      "       [ 0.5832538 , -0.5125943 ],\n",
      "       [-0.6041603 , -0.34467393],\n",
      "       [ 0.02761612,  0.15543413],\n",
      "       [ 0.68286943, -0.15537786],\n",
      "       [ 0.19747151,  0.29896203],\n",
      "       [ 0.6969123 , -0.54942   ]], dtype=float32)>, <tf.Variable 'dense_27/bias:0' shape=(2,) dtype=float32, numpy=array([-0.18128937,  0.18128939], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(model1.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
