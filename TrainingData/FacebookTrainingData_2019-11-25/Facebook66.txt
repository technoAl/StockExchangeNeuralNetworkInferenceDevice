For the first time, LinkedIn included data on its moderation efforts in its biannual transparency report for the H1 2019 reporting period. Previous iterations of the report consisted exclusively of data around government information requests and copyright infringement reports. 






 


        Business Insider Intelligence
      

LinkedIn's ecosystem faces its own unique set of content moderation challenges, including fake accounts, fraudulent jobs, and harassment:With its ramped-up content moderation efforts, LinkedIn is likely hoping to both avoid getting caught up in ongoing public scrutiny of social platforms and protect the platform's professional atmosphere. Both Twitter and Facebook have faced criticism from the press, regulators, and users for the content available on their platform, and that's motivating both self-regulation and the proposal of new policies in Congress.Though LinkedIn serves a wholly different purpose than these two companies, it can still be classified as a social networking platform by any new legislation and would be subject to the same rulings as a result. To that end, LinkedIn is likely erring on the side of proactive disclosure in order to preserve the high standard of trust it has already fostered on its platform: For three years in a row, LinkedIn has ranked as the most-trusted platform among respondents to Business Insider Intelligence's Digital Trust Survey (Enterprise only).Our respondents tend to be early adopters of new technologies, meaning they might be more aware of developments that would affect platform trust in comparison to the general population.Want to read more stories like this one? Here's how to get access: 